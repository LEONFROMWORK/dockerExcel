"""
Korean Template Crawler API
í•œêµ­ì–´ í…œí”Œë¦¿ í¬ë¡¤ë§ API ì—”ë“œí¬ì¸íŠ¸
"""
import logging
from typing import Dict, Any
from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from ...services.korean_template_crawler import korean_template_crawler

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/korean-crawler", tags=["korean_crawler"])


class CrawlingStartRequest(BaseModel):
    force_restart: bool = False
    max_templates_per_category: int = 0  # 0 = ë¬´ì œí•œ


@router.post("/start")
async def start_crawling(
    request: CrawlingStartRequest,
    background_tasks: BackgroundTasks
):
    """
    í•œêµ­ì–´ í…œí”Œë¦¿ í¬ë¡¤ë§ ì‹œì‘
    """
    try:
        # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ì§€ í™•ì¸
        current_progress = korean_template_crawler.get_progress()
        
        if (current_progress['current_status'] not in ['ì¤€ë¹„ ì¤‘', 'ì™„ë£Œ', 'ì˜¤ë¥˜'] and 
            not request.force_restart):
            return JSONResponse(
                status_code=409,
                content={
                    "status": "already_running",
                    "message": "í¬ë¡¤ë§ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤",
                    "current_progress": current_progress
                }
            )
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í¬ë¡¤ë§ ì‹œì‘
        background_tasks.add_task(run_crawling_background)
        
        return {
            "status": "started",
            "message": "í•œêµ­ì–´ í…œí”Œë¦¿ í¬ë¡¤ë§ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            "estimated_duration": "30-60ë¶„",
            "progress_endpoint": "/korean-crawler/progress"
        }
    
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í¬ë¡¤ë§ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")


@router.get("/progress")
async def get_crawling_progress():
    """
    í¬ë¡¤ë§ ì§„í–‰ ìƒí™© ì¡°íšŒ
    """
    try:
        progress = korean_template_crawler.get_progress()
        
        return {
            "status": "success",
            "progress": progress,
            "is_running": progress['current_status'] not in ['ì¤€ë¹„ ì¤‘', 'ì™„ë£Œ', 'ì˜¤ë¥˜']
        }
    
    except Exception as e:
        logger.error(f"ì§„í–‰ ìƒí™© ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì§„í–‰ ìƒí™© ì¡°íšŒ ì‹¤íŒ¨")


@router.post("/stop")
async def stop_crawling():
    """
    í¬ë¡¤ë§ ì¤‘ë‹¨
    """
    try:
        # ì‹¤ì œë¡œëŠ” í¬ë¡¤ëŸ¬ì— ì¤‘ë‹¨ ì‹ í˜¸ë¥¼ ë³´ë‚´ì•¼ í•¨
        # í˜„ì¬ëŠ” ìƒíƒœë§Œ ì—…ë°ì´íŠ¸
        progress = korean_template_crawler.get_progress()
        
        if progress['current_status'] in ['ì¤€ë¹„ ì¤‘', 'ì™„ë£Œ', 'ì˜¤ë¥˜']:
            return {
                "status": "not_running",
                "message": "í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ í¬ë¡¤ë§ì´ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # ì¤‘ë‹¨ ë¡œì§ êµ¬í˜„ í•„ìš” (ì‹¤ì œë¡œëŠ” í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ì— stop ë©”ì„œë“œ ì¶”ê°€)
        return {
            "status": "stopping",
            "message": "í¬ë¡¤ë§ ì¤‘ë‹¨ ìš”ì²­ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
    
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì¤‘ë‹¨ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="í¬ë¡¤ë§ ì¤‘ë‹¨ ì‹¤íŒ¨")


@router.get("/results")
async def get_crawling_results():
    """
    í¬ë¡¤ë§ ê²°ê³¼ ì¡°íšŒ
    """
    try:
        progress = korean_template_crawler.get_progress()
        
        if progress['current_status'] == 'ì™„ë£Œ':
            # í¬ë¡¤ë§ëœ í…œí”Œë¦¿ ëª©ë¡ ë°˜í™˜
            templates = korean_template_crawler.crawled_templates
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ìƒì„±
            category_stats = {}
            for template in templates:
                major = template.category_major
                minor = template.category_minor
                
                if major not in category_stats:
                    category_stats[major] = {}
                if minor not in category_stats[major]:
                    category_stats[major][minor] = 0
                
                category_stats[major][minor] += 1
            
            return {
                "status": "success",
                "summary": {
                    "total_templates": len(templates),
                    "successful_downloads": progress["downloaded_templates"],
                    "failed_downloads": progress["failed_downloads"],
                    "category_stats": category_stats
                },
                "templates": [
                    {
                        "title": t.title,
                        "category_major": t.category_major,
                        "category_minor": t.category_minor,
                        "file_name": t.file_name,
                        "description": t.description[:100] + "..." if len(t.description) > 100 else t.description,
                        "crawled_at": t.crawled_at,
                        "has_local_file": hasattr(t, 'local_path') and t.local_path
                    } for t in templates
                ]
            }
        else:
            return {
                "status": "not_completed",
                "message": f"í¬ë¡¤ë§ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {progress['current_status']}",
                "progress": progress
            }
    
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="í¬ë¡¤ë§ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨")


@router.get("/categories")
async def get_available_categories():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ (í¬ë¡¤ë§ ì™„ë£Œ í›„)
    """
    try:
        templates = korean_template_crawler.crawled_templates
        
        if not templates:
            return {
                "status": "no_data",
                "message": "í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "categories": {}
            }
        
        # ì¹´í…Œê³ ë¦¬ êµ¬ì¡° ìƒì„±
        categories = {}
        for template in templates:
            major = template.category_major
            minor = template.category_minor
            
            if major not in categories:
                categories[major] = {
                    "name": major,
                    "subcategories": {},
                    "total_count": 0
                }
            
            if minor not in categories[major]["subcategories"]:
                categories[major]["subcategories"][minor] = {
                    "name": minor,
                    "count": 0,
                    "templates": []
                }
            
            categories[major]["subcategories"][minor]["count"] += 1
            categories[major]["subcategories"][minor]["templates"].append({
                "title": template.title,
                "file_name": template.file_name
            })
            categories[major]["total_count"] += 1
        
        return {
            "status": "success",
            "categories": categories,
            "total_major_categories": len(categories),
            "total_templates": len(templates)
        }
    
    except Exception as e:
        logger.error(f"ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì‹¤íŒ¨")


@router.get("/download/{category_major}/{category_minor}")
async def get_category_templates(category_major: str, category_minor: str):
    """
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ í…œí”Œë¦¿ ëª©ë¡ ì¡°íšŒ
    """
    try:
        templates = korean_template_crawler.crawled_templates
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ í…œí”Œë¦¿ í•„í„°ë§
        filtered_templates = [
            t for t in templates 
            if t.category_major == category_major and t.category_minor == category_minor
        ]
        
        if not filtered_templates:
            raise HTTPException(
                status_code=404, 
                detail=f"ì¹´í…Œê³ ë¦¬ '{category_major}/{category_minor}'ì—ì„œ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        return {
            "status": "success",
            "category": {
                "major": category_major,
                "minor": category_minor
            },
            "templates": [
                {
                    "title": t.title,
                    "description": t.description,
                    "file_name": t.file_name,
                    "source_url": t.source_url,
                    "crawled_at": t.crawled_at,
                    "local_path": getattr(t, 'local_path', None),
                    "related_files": t.related_files
                } for t in filtered_templates
            ],
            "total_count": len(filtered_templates)
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¹´í…Œê³ ë¦¬ í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¹´í…Œê³ ë¦¬ í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨")


@router.get("/statistics")
async def get_crawling_statistics():
    """
    í¬ë¡¤ë§ í†µê³„ ì •ë³´ ì¡°íšŒ
    """
    try:
        templates = korean_template_crawler.crawled_templates
        progress = korean_template_crawler.get_progress()
        
        if not templates:
            return {
                "status": "no_data",
                "message": "í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # ê¸°ë³¸ í†µê³„
        basic_stats = {
            "total_templates": len(templates),
            "successful_downloads": progress.get("downloaded_templates", 0),
            "failed_downloads": progress.get("failed_downloads", 0),
            "success_rate": round((progress.get("downloaded_templates", 0) / len(templates)) * 100, 2) if templates else 0
        }
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_distribution = {}
        for template in templates:
            major = template.category_major
            if major not in category_distribution:
                category_distribution[major] = 0
            category_distribution[major] += 1
        
        # ì‹œê°„ë³„ í†µê³„ (í¬ë¡¤ë§ ì‹œê°„ ì •ë³´ê°€ ìˆë‹¤ë©´)
        time_stats = {}
        if progress.get('start_time') and progress.get('duration'):
            time_stats = {
                "start_time": progress['start_time'],
                "duration": progress['duration'],
                "templates_per_minute": round(len(templates) / (progress.get('duration_minutes', 1)), 2) if templates else 0
            }
        
        return {
            "status": "success",
            "basic_stats": basic_stats,
            "category_distribution": category_distribution,
            "time_stats": time_stats,
            "quality_metrics": {
                "templates_with_description": len([t for t in templates if t.description and t.description != "ì„¤ëª… ì—†ìŒ"]),
                "templates_with_related_files": len([t for t in templates if t.related_files])
            }
        }
    
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="í†µê³„ ì¡°íšŒ ì‹¤íŒ¨")


@router.get("/cookie-status")
async def check_cookie_status():
    """
    ì¿ í‚¤ íŒŒì¼ ìƒíƒœ í™•ì¸
    """
    try:
        from pathlib import Path
        cookie_file = Path("user_cookies.txt")
        
        if not cookie_file.exists():
            return {
                "status": "missing",
                "message": "user_cookies.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤",
                "has_cookies": False,
                "instruction": "ë¸Œë¼ìš°ì €ì—ì„œ ë¡œê·¸ì¸ í›„ ì¿ í‚¤ë¥¼ ì¶”ì¶œí•˜ì—¬ user_cookies.txt íŒŒì¼ì— ì €ì¥í•˜ì„¸ìš”"
            }
        
        try:
            with open(cookie_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            if not content or content.startswith('#'):
                return {
                    "status": "empty",
                    "message": "ì¿ í‚¤ íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìƒ˜í”Œ ë‚´ìš©ë§Œ ìˆìŠµë‹ˆë‹¤",
                    "has_cookies": False
                }
            
            # ì¿ í‚¤ ê°œìˆ˜ í™•ì¸
            cookies = []
            for line in content.split('\n'):
                if '=' in line and not line.strip().startswith('#'):
                    for cookie_pair in line.split(';'):
                        if '=' in cookie_pair.strip():
                            cookies.append(cookie_pair.strip())
            
            return {
                "status": "valid",
                "message": f"{len(cookies)}ê°œì˜ ì¿ í‚¤ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                "has_cookies": True,
                "cookie_count": len(cookies),
                "cookie_names": [cookie.split('=')[0] for cookie in cookies[:5]]  # ì²˜ìŒ 5ê°œë§Œ
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"ì¿ í‚¤ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}",
                "has_cookies": False
            }
    
    except Exception as e:
        logger.error(f"ì¿ í‚¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì¿ í‚¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨")


@router.post("/test-login")
async def test_login():
    """
    ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸ (ì¿ í‚¤ ìœ íš¨ì„± í™•ì¸)
    """
    try:
        from app.services.korean_template_crawler import KoreanTemplateCrawler
        test_crawler = KoreanTemplateCrawler()
        
        await test_crawler._initialize_session()
        login_result = await test_crawler._login()
        
        # í…ŒìŠ¤íŠ¸ í˜ì´ì§€ ì ‘ì†
        async with test_crawler.session.get(test_crawler.base_url) as response:
            if response.status == 200:
                # ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸
                try:
                    content = await response.text(encoding='utf-8')
                except UnicodeDecodeError:
                    content_bytes = await response.read()
                    try:
                        content = content_bytes.decode('euc-kr')
                    except UnicodeDecodeError:
                        content = content_bytes.decode('cp949', errors='ignore')
                
                # ë¡œê·¸ì¸ ì—¬ë¶€ íŒë‹¨
                is_logged_in = 'logout' in content.lower() or 'ë¡œê·¸ì•„ì›ƒ' in content
                
                await test_crawler.session.close()
                
                return {
                    "status": "success" if is_logged_in else "warning",
                    "message": "ë¡œê·¸ì¸ ì„±ê³µ" if is_logged_in else "ë¡œê·¸ì¸ ìƒíƒœ ë¶ˆí™•ì‹¤",
                    "logged_in": is_logged_in,
                    "response_status": response.status,
                    "content_length": len(content)
                }
            else:
                await test_crawler.session.close()
                return {
                    "status": "error",
                    "message": f"ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨: {response.status}",
                    "logged_in": False
                }
    
    except Exception as e:
        logger.error(f"ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")


@router.get("/cookie-help")
async def get_cookie_help():
    """
    ì¿ í‚¤ ì„¤ì • ë„ì›€ë§
    """
    return {
        "title": "ë¸Œë¼ìš°ì € ì¿ í‚¤ ì¶”ì¶œ ë°©ë²•",
        "current_status": "ì¿ í‚¤ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
        "steps": [
            "1. Chrome/Edgeì—ì„œ https://excel.yesform.com ì ‘ì†",
            "2. ë¡œê·¸ì¸ (j1global / wpdldnjs11!)",
            "3. F12 â†’ Application â†’ Cookies â†’ excel.yesform.com",
            "4. ëª¨ë“  ì¿ í‚¤ ë³µì‚¬",
            "5. user_cookies.txt íŒŒì¼ì— ì €ì¥"
        ],
        "format": "name=value; name2=value2; name3=value3",
        "javascript_helper": "document.cookie",
        "file_location": "python-service/user_cookies.txt",
        "important_notes": [
            "ë¡œê·¸ì¸ ì§í›„ ì¦‰ì‹œ ì¶”ì¶œí•´ì•¼ í•¨",
            "ì„¸ì…˜ ì¿ í‚¤ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë©´ ë§Œë£Œë¨",
            "ê°œì¸ì •ë³´ì´ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ê´€ë¦¬ í•„ìš”"
        ],
        "troubleshooting": {
            "empty_downloads": "ë¡œê·¸ì¸ ì¿ í‚¤ê°€ ë§Œë£Œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ì‹œ ë¡œê·¸ì¸ í›„ ì¿ í‚¤ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”",
            "html_files": "ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ HTMLì¸ ê²½ìš° ì¸ì¦ ì‹¤íŒ¨ì…ë‹ˆë‹¤. ì¿ í‚¤ë¥¼ ì¬ì„¤ì •í•˜ì„¸ìš”"
        }
    }


# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í•¨ìˆ˜
async def run_crawling_background():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í¬ë¡¤ë§ ì‹¤í–‰"""
    try:
        logger.info("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹œì‘")
        result = await korean_template_crawler.start_crawling()
        logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì™„ë£Œ: {result}")
    except Exception as e:
        logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        # ì§„í–‰ ìƒí™©ì„ ì˜¤ë¥˜ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        korean_template_crawler.progress["current_status"] = f"ì˜¤ë¥˜: {str(e)}"
"""
Data Quality Enhancement Service
ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ë° í‘œì¤€í™” ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import openpyxl
from openpyxl.utils import get_column_letter, column_index_from_string
from openpyxl.styles import Font, PatternFill, Alignment
import re
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime, date
import logging
from dataclasses import dataclass
from enum import Enum
import locale
import phonenumbers

class DataType(Enum):
    """ë°ì´í„° íƒ€ì… ì—´ê±°í˜•"""
    TEXT = "text"
    NUMBER = "number"
    DATE = "date"
    EMAIL = "email"
    PHONE = "phone"
    URL = "url"
    CURRENCY = "currency"
    PERCENTAGE = "percentage"
    BOOLEAN = "boolean"
    UNKNOWN = "unknown"

@dataclass
class DataQualityRule:
    """ë°ì´í„° í’ˆì§ˆ ê·œì¹™ ì •ì˜"""
    rule_name: str
    description: str
    severity: str  # critical, high, medium, low
    auto_fixable: bool
    confidence_threshold: float

@dataclass
class DataQualityIssue:
    """ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ"""
    issue_type: str
    location: str
    description: str
    severity: str
    current_value: Any
    suggested_value: Any
    confidence: float
    auto_fixable: bool
    rule_applied: str

class DataQualityEnhancer:
    """ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # ë°ì´í„° í’ˆì§ˆ ê·œì¹™ë“¤
        self.quality_rules = {
            'duplicate_detection': DataQualityRule(
                rule_name='ì¤‘ë³µ ë°ì´í„° ê°ì§€',
                description='ë™ì¼í•œ í–‰ ë˜ëŠ” ê°’ì˜ ì¤‘ë³µì„ ê°ì§€',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.9
            ),
            'missing_data_handling': DataQualityRule(
                rule_name='ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬',
                description='ë¹ˆ ì…€ì´ë‚˜ ëˆ„ë½ëœ ê°’ì„ ì²˜ë¦¬',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.7
            ),
            'data_type_consistency': DataQualityRule(
                rule_name='ë°ì´í„° íƒ€ì… ì¼ê´€ì„±',
                description='ì»¬ëŸ¼ ë‚´ ë°ì´í„° íƒ€ì…ì˜ ì¼ê´€ì„± ê²€ì‚¬',
                severity='high',
                auto_fixable=True,
                confidence_threshold=0.8
            ),
            'date_format_standardization': DataQualityRule(
                rule_name='ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”',
                description='ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ í†µì¼',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.85
            ),
            'number_format_standardization': DataQualityRule(
                rule_name='ìˆ«ì í˜•ì‹ í‘œì¤€í™”',
                description='ìˆ«ìì˜ í‘œê¸° ë°©ì‹ê³¼ ë‹¨ìœ„ë¥¼ ì¼ê´€ë˜ê²Œ ì •ë¦¬',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.9
            ),
            'text_normalization': DataQualityRule(
                rule_name='í…ìŠ¤íŠ¸ ì •ê·œí™”',
                description='ëŒ€ì†Œë¬¸ì, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ì •ê·œí™”',
                severity='low',
                auto_fixable=True,
                confidence_threshold=0.8
            ),
            'email_validation': DataQualityRule(
                rule_name='ì´ë©”ì¼ ìœ íš¨ì„± ê²€ì‚¬',
                description='ì´ë©”ì¼ ì£¼ì†Œì˜ í˜•ì‹ì„ ê²€ì¦',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.95
            ),
            'phone_standardization': DataQualityRule(
                rule_name='ì „í™”ë²ˆí˜¸ í‘œì¤€í™”',
                description='ì „í™”ë²ˆí˜¸ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬',
                severity='medium',
                auto_fixable=True,
                confidence_threshold=0.8
            )
        }
        
        # ë‚ ì§œ íŒ¨í„´ë“¤
        self.date_patterns = [
            (r'\d{4}-\d{2}-\d{2}', '%Y-%m-%d'),  # 2023-12-25
            (r'\d{2}/\d{2}/\d{4}', '%m/%d/%Y'),  # 12/25/2023
            (r'\d{4}/\d{2}/\d{2}', '%Y/%m/%d'),  # 2023/12/25
            (r'\d{2}-\d{2}-\d{4}', '%m-%d-%Y'),  # 12-25-2023
            (r'\d{4}\.\d{2}\.\d{2}', '%Y.%m.%d'), # 2023.12.25
            (r'\d{2}\.\d{2}\.\d{4}', '%m.%d.%Y'), # 12.25.2023
        ]
        
        # í†µí™” ê¸°í˜¸ ë§¤í•‘
        self.currency_symbols = {
            'â‚©': 'KRW',
            '$': 'USD', 
            'â‚¬': 'EUR',
            'Â£': 'GBP',
            'Â¥': 'JPY',
            'ì›': 'KRW',
            'won': 'KRW',
            'dollar': 'USD',
            'euro': 'EUR'
        }
    
    def analyze_data_quality(self, file_path: str) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ì¢…í•© ë¶„ì„"""
        
        try:
            workbook = openpyxl.load_workbook(file_path, data_only=True)
            
            analysis_result = {
                'file_path': file_path,
                'analysis_timestamp': datetime.now().isoformat(),
                'sheets_analyzed': [],
                'overall_quality_score': 0,
                'issues_found': [],
                'data_profile': {},
                'recommendations': []
            }
            
            total_quality_score = 0
            sheets_count = 0
            
            # ê° ì‹œíŠ¸ë³„ ë¶„ì„
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                if sheet.max_row <= 1:  # ë¹ˆ ì‹œíŠ¸ ê±´ë„ˆë›°ê¸°
                    continue
                
                sheet_analysis = self._analyze_sheet_quality(sheet, sheet_name)
                analysis_result['sheets_analyzed'].append(sheet_analysis)
                total_quality_score += sheet_analysis['quality_score']
                sheets_count += 1
                
                # ì‹œíŠ¸ë³„ ì´ìŠˆë“¤ì„ ì „ì²´ ì´ìŠˆ ëª©ë¡ì— ì¶”ê°€
                analysis_result['issues_found'].extend(sheet_analysis['issues'])
            
            # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            analysis_result['overall_quality_score'] = (
                total_quality_score / sheets_count if sheets_count > 0 else 0
            )
            
            # ë°ì´í„° í”„ë¡œíŒŒì¼ ìƒì„±
            analysis_result['data_profile'] = self._generate_data_profile(analysis_result['sheets_analyzed'])
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            analysis_result['recommendations'] = self._generate_quality_recommendations(
                analysis_result['issues_found'], 
                analysis_result['overall_quality_score']
            )
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'error': f'ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                'file_path': file_path
            }
    
    def enhance_data_quality(self, file_path: str, enhancement_options: Dict[str, bool] = None) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ì ìš©"""
        
        if enhancement_options is None:
            enhancement_options = {
                'remove_duplicates': True,
                'fill_missing_data': True,
                'standardize_formats': True,
                'normalize_text': True,
                'validate_emails': True,
                'standardize_phones': True,
                'optimize_data_types': True
            }
        
        try:
            workbook = openpyxl.load_workbook(file_path, data_only=False)
            
            enhancement_result = {
                'original_file': file_path,
                'enhancements_applied': [],
                'quality_improvements': {},
                'summary': {
                    'sheets_processed': 0,
                    'total_changes': 0,
                    'quality_score_before': 0,
                    'quality_score_after': 0
                }
            }
            
            # ì²˜ë¦¬ ì „ í’ˆì§ˆ ì ìˆ˜
            pre_analysis = self.analyze_data_quality(file_path)
            enhancement_result['summary']['quality_score_before'] = pre_analysis.get('overall_quality_score', 0)
            
            # ê° ì‹œíŠ¸ë³„ í’ˆì§ˆ í–¥ìƒ ì ìš©
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                if sheet.max_row <= 1:
                    continue
                
                sheet_enhancements = self._enhance_sheet_quality(sheet, sheet_name, enhancement_options)
                enhancement_result['enhancements_applied'].append(sheet_enhancements)
                enhancement_result['summary']['sheets_processed'] += 1
                enhancement_result['summary']['total_changes'] += sheet_enhancements.get('changes_count', 0)
            
            # í–¥ìƒëœ íŒŒì¼ ì €ì¥
            output_path = file_path.replace('.xlsx', '_enhanced.xlsx')
            workbook.save(output_path)
            enhancement_result['enhanced_file_path'] = output_path
            
            # ì²˜ë¦¬ í›„ í’ˆì§ˆ ì ìˆ˜ (ê°„ëµ ê³„ì‚°)
            enhancement_result['summary']['quality_score_after'] = min(
                enhancement_result['summary']['quality_score_before'] + 
                (enhancement_result['summary']['total_changes'] * 0.5), 
                100
            )
            
            return enhancement_result
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'error': f'ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ì‹¤íŒ¨: {str(e)}',
                'file_path': file_path
            }
    
    def _analyze_sheet_quality(self, sheet, sheet_name: str) -> Dict[str, Any]:
        """ê°œë³„ ì‹œíŠ¸ì˜ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        
        # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        data = []
        for row in sheet.iter_rows(values_only=True):
            data.append(row)
        
        if not data or len(data) < 2:
            return {
                'sheet_name': sheet_name,
                'quality_score': 100,  # ë¹ˆ ì‹œíŠ¸ëŠ” ì™„ë²½í•œ ì ìˆ˜
                'issues': [],
                'data_stats': {}
            }
        
        # í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
        headers = data[0] if data[0] else [f"Column_{i+1}" for i in range(len(data[0]))]
        data_rows = data[1:] if len(data) > 1 else []
        
        df = pd.DataFrame(data_rows, columns=headers)
        
        sheet_analysis = {
            'sheet_name': sheet_name,
            'quality_score': 100,  # ê¸°ë³¸ ì ìˆ˜ì—ì„œ ì°¨ê°
            'issues': [],
            'data_stats': {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'non_empty_cells': 0,
                'data_types_detected': {}
            }
        }
        
        quality_deductions = 0
        
        # 1. ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
        duplicate_issues = self._detect_duplicates(df, sheet_name)
        sheet_analysis['issues'].extend(duplicate_issues)
        quality_deductions += len(duplicate_issues) * 2
        
        # 2. ëˆ„ë½ ë°ì´í„° ê²€ì‚¬
        missing_issues = self._detect_missing_data(df, sheet_name)
        sheet_analysis['issues'].extend(missing_issues)
        quality_deductions += len(missing_issues) * 1
        
        # 3. ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ê²€ì‚¬
        type_issues = self._detect_data_type_issues(df, sheet_name)
        sheet_analysis['issues'].extend(type_issues)
        quality_deductions += len(type_issues) * 3
        
        # 4. ë‚ ì§œ í˜•ì‹ ê²€ì‚¬
        date_issues = self._detect_date_format_issues(df, sheet_name)
        sheet_analysis['issues'].extend(date_issues)
        quality_deductions += len(date_issues) * 2
        
        # 5. ìˆ«ì í˜•ì‹ ê²€ì‚¬
        number_issues = self._detect_number_format_issues(df, sheet_name)
        sheet_analysis['issues'].extend(number_issues)
        quality_deductions += len(number_issues) * 2
        
        # 6. í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì‚¬
        text_issues = self._detect_text_quality_issues(df, sheet_name)
        sheet_analysis['issues'].extend(text_issues)
        quality_deductions += len(text_issues) * 1
        
        # 7. ì´ë©”ì¼ ìœ íš¨ì„± ê²€ì‚¬
        email_issues = self._detect_email_issues(df, sheet_name)
        sheet_analysis['issues'].extend(email_issues)
        quality_deductions += len(email_issues) * 2
        
        # 8. ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
        phone_issues = self._detect_phone_issues(df, sheet_name)
        sheet_analysis['issues'].extend(phone_issues)
        quality_deductions += len(phone_issues) * 1
        
        # ë°ì´í„° í†µê³„ ê³„ì‚°
        sheet_analysis['data_stats']['non_empty_cells'] = df.count().sum()
        sheet_analysis['data_stats']['data_types_detected'] = self._analyze_data_types(df)
        
        # ìµœì¢… í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        sheet_analysis['quality_score'] = max(0, 100 - quality_deductions)
        
        return sheet_analysis
    
    def _enhance_sheet_quality(self, sheet, sheet_name: str, options: Dict[str, bool]) -> Dict[str, Any]:
        """ê°œë³„ ì‹œíŠ¸ì˜ ë°ì´í„° í’ˆì§ˆ í–¥ìƒ"""
        
        enhancement_result = {
            'sheet_name': sheet_name,
            'changes_count': 0,
            'enhancements': []
        }
        
        # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        data = []
        for row in sheet.iter_rows(values_only=True):
            data.append(row)
        
        if not data or len(data) < 2:
            return enhancement_result
        
        headers = data[0] if data[0] else [f"Column_{i+1}" for i in range(len(data[0]))]
        data_rows = data[1:] if len(data) > 1 else []
        df = pd.DataFrame(data_rows, columns=headers)
        
        # ì¤‘ë³µ ì œê±°
        if options.get('remove_duplicates', True):
            duplicate_count = self._remove_duplicates(sheet, df)
            if duplicate_count > 0:
                enhancement_result['enhancements'].append(f"{duplicate_count}ê°œ ì¤‘ë³µ í–‰ ì œê±°")
                enhancement_result['changes_count'] += duplicate_count
        
        # ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬
        if options.get('fill_missing_data', True):
            filled_count = self._fill_missing_data(sheet, df)
            if filled_count > 0:
                enhancement_result['enhancements'].append(f"{filled_count}ê°œ ë¹ˆ ì…€ ì²˜ë¦¬")
                enhancement_result['changes_count'] += filled_count
        
        # í˜•ì‹ í‘œì¤€í™”
        if options.get('standardize_formats', True):
            format_changes = self._standardize_formats(sheet, df)
            if format_changes > 0:
                enhancement_result['enhancements'].append(f"{format_changes}ê°œ í˜•ì‹ í‘œì¤€í™”")
                enhancement_result['changes_count'] += format_changes
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        if options.get('normalize_text', True):
            text_changes = self._normalize_text_data(sheet, df)
            if text_changes > 0:
                enhancement_result['enhancements'].append(f"{text_changes}ê°œ í…ìŠ¤íŠ¸ ì •ê·œí™”")
                enhancement_result['changes_count'] += text_changes
        
        return enhancement_result
    
    def _detect_duplicates(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ì¤‘ë³µ ë°ì´í„° ê°ì§€"""
        
        issues = []
        
        # ì „ì²´ í–‰ ì¤‘ë³µ ê²€ì‚¬
        duplicate_rows = df.duplicated()
        if duplicate_rows.any():
            duplicate_count = duplicate_rows.sum()
            issues.append(DataQualityIssue(
                issue_type='duplicate_rows',
                location=f"{sheet_name}!ì „ì²´",
                description=f"{duplicate_count}ê°œì˜ ì¤‘ë³µ í–‰ ë°œê²¬",
                severity='medium',
                current_value=f"{duplicate_count} ì¤‘ë³µ í–‰",
                suggested_value="ì¤‘ë³µ í–‰ ì œê±°",
                confidence=0.95,
                auto_fixable=True,
                rule_applied='duplicate_detection'
            ))
        
        # ì»¬ëŸ¼ë³„ ì¤‘ë³µê°’ ê²€ì‚¬ (í‚¤ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ê²½ìš°)
        for col in df.columns:
            if col and ('id' in str(col).lower() or 'key' in str(col).lower()):
                col_duplicates = df[col].duplicated()
                if col_duplicates.any():
                    duplicate_count = col_duplicates.sum()
                    issues.append(DataQualityIssue(
                        issue_type='duplicate_values',
                        location=f"{sheet_name}!{col}",
                        description=f"í‚¤ ì»¬ëŸ¼ '{col}'ì—ì„œ {duplicate_count}ê°œ ì¤‘ë³µê°’ ë°œê²¬",
                        severity='high',
                        current_value=f"{duplicate_count} ì¤‘ë³µê°’",
                        suggested_value="ì¤‘ë³µê°’ ì œê±° ë˜ëŠ” ìˆ˜ì •",
                        confidence=0.9,
                        auto_fixable=False,  # í‚¤ ì»¬ëŸ¼ì€ ìˆ˜ë™ ê²€í†  í•„ìš”
                        rule_applied='duplicate_detection'
                    ))
        
        return issues
    
    def _detect_missing_data(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ëˆ„ë½ ë°ì´í„° ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
            
            missing_count = df[col].isna().sum()
            total_count = len(df)
            missing_percentage = (missing_count / total_count) * 100
            
            if missing_count > 0:
                severity = 'high' if missing_percentage > 50 else 'medium' if missing_percentage > 20 else 'low'
                
                col_letter = get_column_letter(col_idx + 1)
                issues.append(DataQualityIssue(
                    issue_type='missing_data',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ {missing_count}ê°œ ê°’ ëˆ„ë½ ({missing_percentage:.1f}%)",
                    severity=severity,
                    current_value=f"{missing_count} ëˆ„ë½ê°’",
                    suggested_value=self._suggest_missing_data_treatment(df[col], missing_percentage),
                    confidence=0.8 if missing_percentage < 30 else 0.6,
                    auto_fixable=missing_percentage < 30,
                    rule_applied='missing_data_handling'
                ))
        
        return issues
    
    def _detect_data_type_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ë¬¸ì œ ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
                
            col_data = df[col].dropna()
            if len(col_data) == 0:
                continue
            
            # ë°ì´í„° íƒ€ì… ë¶„ì„
            type_analysis = self._analyze_column_types(col_data)
            
            if len(type_analysis) > 1:  # ì—¬ëŸ¬ íƒ€ì…ì´ ì„ì—¬ ìˆëŠ” ê²½ìš°
                col_letter = get_column_letter(col_idx + 1)
                
                # ìˆ«ìê°€ í…ìŠ¤íŠ¸ë¡œ ì €ì¥ëœ ê²½ìš°
                if DataType.NUMBER in type_analysis and DataType.TEXT in type_analysis:
                    text_numbers = self._find_text_numbers(col_data)
                    if len(text_numbers) > len(col_data) * 0.3:  # 30% ì´ìƒ
                        issues.append(DataQualityIssue(
                            issue_type='text_stored_as_number',
                            location=f"{sheet_name}!{col_letter}:{col_letter}",
                            description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ ìˆ«ìê°€ í…ìŠ¤íŠ¸ë¡œ ì €ì¥ë¨",
                            severity='medium',
                            current_value=f"{len(text_numbers)}ê°œ í…ìŠ¤íŠ¸ ìˆ«ì",
                            suggested_value="ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜",
                            confidence=0.9,
                            auto_fixable=True,
                            rule_applied='data_type_consistency'
                        ))
                
                # í˜¼ì¬ëœ ë°ì´í„° íƒ€ì…
                issues.append(DataQualityIssue(
                    issue_type='mixed_data_types',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ ì—¬ëŸ¬ ë°ì´í„° íƒ€ì… í˜¼ì¬: {', '.join([t.value for t in type_analysis])}",
                    severity='high',
                    current_value=list(type_analysis),
                    suggested_value="ì¼ê´€ëœ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ í†µì¼",
                    confidence=0.7,
                    auto_fixable=False,
                    rule_applied='data_type_consistency'
                ))
        
        return issues
    
    def _detect_date_format_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ë‚ ì§œ í˜•ì‹ ë¬¸ì œ ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
                
            col_data = df[col].dropna().astype(str)
            date_formats_found = set()
            date_values = []
            
            for value in col_data:
                for pattern, format_str in self.date_patterns:
                    if re.match(pattern, value.strip()):
                        date_formats_found.add(format_str)
                        date_values.append(value)
                        break
            
            # ë‚ ì§œë¡œ ë³´ì´ëŠ” ê°’ë“¤ì´ ìˆê³ , ì—¬ëŸ¬ í˜•ì‹ì´ ì„ì—¬ ìˆëŠ” ê²½ìš°
            if len(date_values) > len(col_data) * 0.5 and len(date_formats_found) > 1:
                col_letter = get_column_letter(col_idx + 1)
                issues.append(DataQualityIssue(
                    issue_type='inconsistent_date_format',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ {len(date_formats_found)}ê°€ì§€ ë‚ ì§œ í˜•ì‹ í˜¼ì¬",
                    severity='medium',
                    current_value=list(date_formats_found),
                    suggested_value="í‘œì¤€ ë‚ ì§œ í˜•ì‹(YYYY-MM-DD)ìœ¼ë¡œ í†µì¼",
                    confidence=0.85,
                    auto_fixable=True,
                    rule_applied='date_format_standardization'
                ))
        
        return issues
    
    def _detect_number_format_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ìˆ«ì í˜•ì‹ ë¬¸ì œ ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
                
            col_data = df[col].dropna().astype(str)
            
            # í†µí™” ê¸°í˜¸ í˜¼ì¬ ê²€ì‚¬
            currency_symbols_found = set()
            for value in col_data:
                for symbol in self.currency_symbols.keys():
                    if symbol in value:
                        currency_symbols_found.add(symbol)
            
            if len(currency_symbols_found) > 1:
                col_letter = get_column_letter(col_idx + 1)
                issues.append(DataQualityIssue(
                    issue_type='mixed_currency_symbols',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ ì—¬ëŸ¬ í†µí™” ê¸°í˜¸ í˜¼ì¬: {', '.join(currency_symbols_found)}",
                    severity='medium',
                    current_value=list(currency_symbols_found),
                    suggested_value="ì¼ê´€ëœ í†µí™” ê¸°í˜¸ë¡œ í†µì¼",
                    confidence=0.8,
                    auto_fixable=True,
                    rule_applied='number_format_standardization'
                ))
            
            # ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ë¶ˆì¼ì¹˜ ê²€ì‚¬
            comma_format = sum(1 for v in col_data if ',' in v and re.match(r'[\d,]+', v))
            no_comma_format = sum(1 for v in col_data if v.isdigit() and len(v) > 3)
            
            if comma_format > 0 and no_comma_format > 0:
                col_letter = get_column_letter(col_idx + 1)
                issues.append(DataQualityIssue(
                    issue_type='inconsistent_number_format',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì‚¬ìš© ë¶ˆì¼ì¹˜",
                    severity='low',
                    current_value={"ì½¤ë§ˆ_ì‚¬ìš©": comma_format, "ì½¤ë§ˆ_ë¯¸ì‚¬ìš©": no_comma_format},
                    suggested_value="ì¼ê´€ëœ ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì ìš©",
                    confidence=0.9,
                    auto_fixable=True,
                    rule_applied='number_format_standardization'
                ))
        
        return issues
    
    def _detect_text_quality_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¬¸ì œ ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
                
            col_data = df[col].dropna().astype(str)
            text_issues = []
            
            # ì•ë’¤ ê³µë°± ë¬¸ì œ
            leading_trailing_spaces = sum(1 for v in col_data if v != v.strip())
            if leading_trailing_spaces > 0:
                text_issues.append(f"{leading_trailing_spaces}ê°œ ê°’ì— ì•ë’¤ ê³µë°±")
            
            # ì—°ì† ê³µë°± ë¬¸ì œ
            multiple_spaces = sum(1 for v in col_data if '  ' in v)
            if multiple_spaces > 0:
                text_issues.append(f"{multiple_spaces}ê°œ ê°’ì— ì—°ì† ê³µë°±")
            
            # ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜ (ê°™ì€ ë‹¨ì–´ì˜ ë‹¤ë¥¸ ì¼€ì´ìŠ¤)
            case_variations = self._detect_case_variations(col_data)
            if case_variations:
                text_issues.append(f"{len(case_variations)}ê°œ ë‹¨ì–´ì˜ ëŒ€ì†Œë¬¸ì ë¶ˆì¼ì¹˜")
            
            if text_issues:
                col_letter = get_column_letter(col_idx + 1)
                issues.append(DataQualityIssue(
                    issue_type='text_quality_issues',
                    location=f"{sheet_name}!{col_letter}:{col_letter}",
                    description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¬¸ì œ: {', '.join(text_issues)}",
                    severity='low',
                    current_value=text_issues,
                    suggested_value="í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°± ì œê±°, ëŒ€ì†Œë¬¸ì í†µì¼)",
                    confidence=0.9,
                    auto_fixable=True,
                    rule_applied='text_normalization'
                ))
        
        return issues
    
    def _detect_email_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ì´ë©”ì¼ ì£¼ì†Œ ìœ íš¨ì„± ë¬¸ì œ ê°ì§€"""
        
        issues = []
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
            
            # ì´ë©”ì¼ë¡œ ì¶”ì •ë˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
            if 'email' in str(col).lower() or 'mail' in str(col).lower():
                col_data = df[col].dropna().astype(str)
                invalid_emails = []
                
                for value in col_data:
                    if not re.match(email_pattern, value.strip()):
                        invalid_emails.append(value)
                
                if invalid_emails:
                    col_letter = get_column_letter(col_idx + 1)
                    issues.append(DataQualityIssue(
                        issue_type='invalid_email_format',
                        location=f"{sheet_name}!{col_letter}:{col_letter}",
                        description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ {len(invalid_emails)}ê°œ ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹",
                        severity='medium',
                        current_value=f"{len(invalid_emails)} ì˜ëª»ëœ ì´ë©”ì¼",
                        suggested_value="ìœ íš¨í•œ ì´ë©”ì¼ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •",
                        confidence=0.95,
                        auto_fixable=False,  # ì´ë©”ì¼ì€ ìˆ˜ë™ ê²€í†  í•„ìš”
                        rule_applied='email_validation'
                    ))
        
        return issues
    
    def _detect_phone_issues(self, df: pd.DataFrame, sheet_name: str) -> List[DataQualityIssue]:
        """ì „í™”ë²ˆí˜¸ í˜•ì‹ ë¬¸ì œ ê°ì§€"""
        
        issues = []
        
        for col_idx, col in enumerate(df.columns):
            if col is None:
                continue
            
            # ì „í™”ë²ˆí˜¸ë¡œ ì¶”ì •ë˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
            if any(keyword in str(col).lower() for keyword in ['phone', 'tel', 'ì „í™”', 'íœ´ëŒ€í°', 'mobile']):
                col_data = df[col].dropna().astype(str)
                format_variations = set()
                
                for value in col_data:
                    # ì „í™”ë²ˆí˜¸ íŒ¨í„´ ë¶„ì„
                    cleaned = re.sub(r'[^\d-]', '', value)
                    if len(cleaned) >= 8:  # ìµœì†Œ ì „í™”ë²ˆí˜¸ ê¸¸ì´
                        format_variations.add(self._get_phone_format_pattern(cleaned))
                
                if len(format_variations) > 1:
                    col_letter = get_column_letter(col_idx + 1)
                    issues.append(DataQualityIssue(
                        issue_type='inconsistent_phone_format',
                        location=f"{sheet_name}!{col_letter}:{col_letter}",
                        description=f"ì»¬ëŸ¼ '{col}'ì—ì„œ {len(format_variations)}ê°€ì§€ ì „í™”ë²ˆí˜¸ í˜•ì‹ í˜¼ì¬",
                        severity='medium',
                        current_value=list(format_variations),
                        suggested_value="í‘œì¤€ ì „í™”ë²ˆí˜¸ í˜•ì‹ìœ¼ë¡œ í†µì¼ (ì˜ˆ: 010-1234-5678)",
                        confidence=0.8,
                        auto_fixable=True,
                        rule_applied='phone_standardization'
                    ))
        
        return issues
    
    # í—¬í¼ ë©”ì„œë“œë“¤
    def _analyze_column_types(self, series: pd.Series) -> set:
        """ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ë“¤ì„ ë¶„ì„"""
        types_found = set()
        
        for value in series:
            if pd.isna(value):
                continue
                
            str_value = str(value).strip()
            
            # ìˆ«ì ì²´í¬
            if self._is_number(str_value):
                types_found.add(DataType.NUMBER)
            # ë‚ ì§œ ì²´í¬
            elif self._is_date(str_value):
                types_found.add(DataType.DATE)
            # ì´ë©”ì¼ ì²´í¬
            elif self._is_email(str_value):
                types_found.add(DataType.EMAIL)
            # URL ì²´í¬
            elif self._is_url(str_value):
                types_found.add(DataType.URL)
            # ì „í™”ë²ˆí˜¸ ì²´í¬
            elif self._is_phone(str_value):
                types_found.add(DataType.PHONE)
            else:
                types_found.add(DataType.TEXT)
        
        return types_found
    
    def _is_number(self, value: str) -> bool:
        """ìˆ«ìì¸ì§€ í™•ì¸"""
        try:
            float(value.replace(',', '').replace('â‚©', '').replace('$', ''))
            return True
        except ValueError:
            return False
    
    def _is_date(self, value: str) -> bool:
        """ë‚ ì§œì¸ì§€ í™•ì¸"""
        for pattern, _ in self.date_patterns:
            if re.match(pattern, value):
                return True
        return False
    
    def _is_email(self, value: str) -> bool:
        """ì´ë©”ì¼ì¸ì§€ í™•ì¸"""
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        return bool(re.match(email_pattern, value))
    
    def _is_url(self, value: str) -> bool:
        """URLì¸ì§€ í™•ì¸"""
        url_pattern = r'https?://[^\s]+'
        return bool(re.match(url_pattern, value))
    
    def _is_phone(self, value: str) -> bool:
        """ì „í™”ë²ˆí˜¸ì¸ì§€ í™•ì¸"""
        phone_pattern = r'[\d\-\(\)\+\s]{8,}'
        return bool(re.match(phone_pattern, value))
    
    def _find_text_numbers(self, series: pd.Series) -> List:
        """í…ìŠ¤íŠ¸ë¡œ ì €ì¥ëœ ìˆ«ìë“¤ ì°¾ê¸°"""
        text_numbers = []
        for value in series:
            if isinstance(value, str) and self._is_number(value):
                text_numbers.append(value)
        return text_numbers
    
    def _suggest_missing_data_treatment(self, series: pd.Series, missing_percentage: float) -> str:
        """ëˆ„ë½ ë°ì´í„° ì²˜ë¦¬ ë°©ë²• ì œì•ˆ"""
        if missing_percentage > 70:
            return "ì»¬ëŸ¼ ì œê±° ê³ ë ¤"
        elif missing_percentage > 30:
            return "ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸° ë˜ëŠ” í•´ë‹¹ í–‰ ì œê±°"
        else:
            # ë°ì´í„° íƒ€ì…ì— ë”°ë¥¸ ì œì•ˆ
            non_null_data = series.dropna()
            if len(non_null_data) == 0:
                return "ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°"
            
            sample_value = non_null_data.iloc[0] if len(non_null_data) > 0 else None
            
            if isinstance(sample_value, (int, float)):
                return "í‰ê· ê°’ ë˜ëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°"
            elif self._is_date(str(sample_value)):
                return "ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œë¡œ ì±„ìš°ê¸°"
            else:
                return "ê°€ì¥ ë¹ˆë²ˆí•œ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°"
    
    def _detect_case_variations(self, series: pd.Series) -> List:
        """ëŒ€ì†Œë¬¸ì ë³€í˜•ë“¤ ê°ì§€"""
        word_variations = {}
        for value in series:
            lower_value = value.lower()
            if lower_value not in word_variations:
                word_variations[lower_value] = set()
            word_variations[lower_value].add(value)
        
        variations = []
        for word, cases in word_variations.items():
            if len(cases) > 1:
                variations.extend(list(cases))
        
        return variations
    
    def _get_phone_format_pattern(self, phone: str) -> str:
        """ì „í™”ë²ˆí˜¸ í˜•ì‹ íŒ¨í„´ ì¶”ì¶œ"""
        if '-' in phone:
            parts = phone.split('-')
            return '-'.join(['X' * len(part) for part in parts])
        elif len(phone) == 11:
            return 'XXXXXXXXXXX'
        elif len(phone) == 10:
            return 'XXXXXXXXXX'
        else:
            return f'X({len(phone)}digits)'
    
    # ì‹¤ì œ ë°ì´í„° ìˆ˜ì • ë©”ì„œë“œë“¤
    def _remove_duplicates(self, sheet, df: pd.DataFrame) -> int:
        """ì¤‘ë³µ í–‰ ì œê±°"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Excel ì‹œíŠ¸ì—ì„œ ì¤‘ë³µ í–‰ì„ ì°¾ì•„ ì‚­ì œ
        duplicate_rows = df.duplicated()
        duplicate_count = duplicate_rows.sum()
        
        # ì—¬ê¸°ì„œëŠ” ì‹¤ì œ ì‚­ì œ ë¡œì§ì„ êµ¬í˜„í•´ì•¼ í•¨
        # ì˜ˆì‹œë¡œ ê°œìˆ˜ë§Œ ë°˜í™˜
        return duplicate_count
    
    def _fill_missing_data(self, sheet, df: pd.DataFrame) -> int:
        """ëˆ„ë½ëœ ë°ì´í„° ì±„ìš°ê¸°"""
        filled_count = 0
        
        for col in df.columns:
            missing_count = df[col].isna().sum()
            if missing_count > 0:
                # ë°ì´í„° íƒ€ì…ì— ë”°ë¥¸ ì ì ˆí•œ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                if df[col].dtype in ['int64', 'float64']:
                    fill_value = df[col].median()
                else:
                    fill_value = df[col].mode().iloc[0] if not df[col].mode().empty else ""
                
                # ì‹¤ì œ Excel ì‹œíŠ¸ì— ê°’ ì…ë ¥
                # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ê°œìˆ˜ë§Œ ì¦ê°€
                filled_count += missing_count
        
        return filled_count
    
    def _standardize_formats(self, sheet, df: pd.DataFrame) -> int:
        """í˜•ì‹ í‘œì¤€í™”"""
        changes_count = 0
        
        # ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”
        for col in df.columns:
            col_data = df[col].dropna().astype(str)
            for idx, value in enumerate(col_data):
                for pattern, format_str in self.date_patterns:
                    if re.match(pattern, value):
                        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        try:
                            date_obj = datetime.strptime(value, format_str)
                            standardized = date_obj.strftime('%Y-%m-%d')
                            if standardized != value:
                                changes_count += 1
                        except ValueError:
                            continue
                        break
        
        return changes_count
    
    def _normalize_text_data(self, sheet, df: pd.DataFrame) -> int:
        """í…ìŠ¤íŠ¸ ë°ì´í„° ì •ê·œí™”"""
        changes_count = 0
        
        for col in df.columns:
            col_data = df[col].dropna().astype(str)
            for idx, value in enumerate(col_data):
                original = value
                normalized = value.strip()  # ê³µë°± ì œê±°
                normalized = re.sub(r'\s+', ' ', normalized)  # ì—°ì† ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
                
                if normalized != original:
                    changes_count += 1
        
        return changes_count
    
    def _generate_data_profile(self, sheets_analysis: List[Dict]) -> Dict[str, Any]:
        """ë°ì´í„° í”„ë¡œíŒŒì¼ ìƒì„±"""
        
        total_rows = sum(sheet.get('data_stats', {}).get('total_rows', 0) for sheet in sheets_analysis)
        total_columns = sum(sheet.get('data_stats', {}).get('total_columns', 0) for sheet in sheets_analysis)
        
        return {
            'total_sheets': len(sheets_analysis),
            'total_rows': total_rows,
            'total_columns': total_columns,
            'average_quality_score': sum(sheet.get('quality_score', 0) for sheet in sheets_analysis) / len(sheets_analysis) if sheets_analysis else 0
        }
    
    def _generate_quality_recommendations(self, issues: List[DataQualityIssue], overall_score: float) -> List[str]:
        """í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        if overall_score < 50:
            recommendations.append("ğŸš¨ ë°ì´í„° í’ˆì§ˆì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. ì „ë©´ì ì¸ ë°ì´í„° ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        elif overall_score < 70:
            recommendations.append("âš ï¸ ë°ì´í„° í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif overall_score < 90:
            recommendations.append("âœ… ë°ì´í„° í’ˆì§ˆì´ ì–‘í˜¸í•˜ì§€ë§Œ ëª‡ ê°€ì§€ ê°œì„ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            recommendations.append("ğŸ‰ ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        
        # ì´ìŠˆ íƒ€ì…ë³„ ê¶Œì¥ì‚¬í•­
        issue_types = {}
        for issue in issues:
            if issue.issue_type not in issue_types:
                issue_types[issue.issue_type] = 0
            issue_types[issue.issue_type] += 1
        
        if issue_types.get('duplicate_rows', 0) > 0:
            recommendations.append("ğŸ—‚ï¸ ì¤‘ë³µ ë°ì´í„°ë¥¼ ì œê±°í•˜ì—¬ ë°ì´í„° ì •í™•ì„±ì„ ë†’ì´ì„¸ìš”.")
        
        if issue_types.get('missing_data', 0) > 0:
            recommendations.append("ğŸ“ ëˆ„ë½ëœ ë°ì´í„°ë¥¼ ì ì ˆí•œ ê°’ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜ ì œê±°í•˜ì„¸ìš”.")
        
        if issue_types.get('mixed_data_types', 0) > 0:
            recommendations.append("ğŸ”§ ë°ì´í„° íƒ€ì…ì„ ì¼ê´€ë˜ê²Œ ì •ë¦¬í•˜ì—¬ ë¶„ì„ íš¨ìœ¨ì„ ë†’ì´ì„¸ìš”.")
        
        if issue_types.get('inconsistent_date_format', 0) > 0:
            recommendations.append("ğŸ“… ë‚ ì§œ í˜•ì‹ì„ í‘œì¤€í™”í•˜ì—¬ ì‹œê³„ì—´ ë¶„ì„ì„ ìš©ì´í•˜ê²Œ í•˜ì„¸ìš”.")
        
        return recommendations
    
    def _analyze_data_types(self, df: pd.DataFrame) -> Dict[str, int]:
        """ë°ì´í„° íƒ€ì…ë³„ ì»¬ëŸ¼ ìˆ˜ ë¶„ì„"""
        
        type_counts = {
            'text': 0,
            'number': 0,
            'date': 0,
            'mixed': 0
        }
        
        for col in df.columns:
            if col is None:
                continue
            
            col_data = df[col].dropna()
            if len(col_data) == 0:
                continue
            
            types_found = self._analyze_column_types(col_data)
            
            if len(types_found) > 1:
                type_counts['mixed'] += 1
            elif DataType.NUMBER in types_found:
                type_counts['number'] += 1
            elif DataType.DATE in types_found:
                type_counts['date'] += 1
            else:
                type_counts['text'] += 1
        
        return type_counts
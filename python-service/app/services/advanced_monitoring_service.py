"""
ê³ ê¸‰ ì‘ì—… ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
ì‹¤ì‹œê°„ ì§„í–‰ë¥ , ì‹¤íŒ¨ ê°ì§€, ì•Œë¦¼ ì‹œìŠ¤í…œ
ë¹„ì¦ˆë‹ˆìŠ¤ KPI ì¤‘ì‹¬ ëª¨ë‹ˆí„°ë§
"""

import time
import logging
import asyncio
import threading
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Callable, Set
from enum import Enum
from datetime import datetime, timedelta
from collections import defaultdict, deque
import json
import psutil
import websockets
import asyncio

from app.services.strategic_batch_manager import (
    get_batch_manager,
    JobStatus,
    JobType,
    JobPriority
)

logger = logging.getLogger(__name__)

# ===== ëª¨ë‹ˆí„°ë§ ë°ì´í„° ëª¨ë¸ =====

class AlertSeverity(Enum):
    """ì•Œë¦¼ ì‹¬ê°ë„"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ ìœ í˜•"""
    COUNTER = "counter"        # ëˆ„ì  ì¹´ìš´í„°
    GAUGE = "gauge"           # í˜„ì¬ ê°’
    HISTOGRAM = "histogram"    # ë¶„í¬
    RATE = "rate"             # ë¹„ìœ¨

@dataclass
class MonitoringAlert:
    """ëª¨ë‹ˆí„°ë§ ì•Œë¦¼"""
    alert_id: str
    severity: AlertSeverity
    title: str
    message: str
    source: str
    timestamp: datetime = field(default_factory=datetime.now)
    acknowledged: bool = False
    resolved: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "alert_id": self.alert_id,
            "severity": self.severity.value,
            "title": self.title,
            "message": self.message,
            "source": self.source,
            "timestamp": self.timestamp.isoformat(),
            "acknowledged": self.acknowledged,
            "resolved": self.resolved,
            "metadata": self.metadata
        }

@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    name: str
    value: float
    metric_type: MetricType
    unit: str = ""
    tags: Dict[str, str] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "value": self.value,
            "type": self.metric_type.value,
            "unit": self.unit,
            "tags": self.tags,
            "timestamp": self.timestamp.isoformat()
        }

@dataclass
class JobProgressInfo:
    """ì‘ì—… ì§„í–‰ ì •ë³´"""
    job_id: str
    job_type: str
    priority: str
    progress_percent: float
    estimated_remaining_seconds: int
    current_stage: str
    stages_completed: int
    total_stages: int
    throughput_per_second: float = 0.0
    error_messages: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "job_id": self.job_id,
            "job_type": self.job_type,
            "priority": self.priority,
            "progress_percent": self.progress_percent,
            "estimated_remaining_seconds": self.estimated_remaining_seconds,
            "current_stage": self.current_stage,
            "stages_completed": self.stages_completed,
            "total_stages": self.total_stages,
            "throughput_per_second": self.throughput_per_second,
            "error_messages": self.error_messages,
            "warnings": self.warnings
        }

# ===== ì¸í„°í˜ì´ìŠ¤ ì •ì˜ =====

class AlertHandler(ABC):
    """ì•Œë¦¼ ì²˜ë¦¬ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def send_alert(self, alert: MonitoringAlert) -> bool:
        """ì•Œë¦¼ ì „ì†¡"""
        pass

class MetricCollector(ABC):
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def collect_metrics(self) -> List[PerformanceMetric]:
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        pass

# ===== ì•Œë¦¼ ì²˜ë¦¬ê¸° êµ¬í˜„ =====

class ConsoleAlertHandler(AlertHandler):
    """ì½˜ì†” ì•Œë¦¼ ì²˜ë¦¬ê¸°"""
    
    async def send_alert(self, alert: MonitoringAlert) -> bool:
        severity_icons = {
            AlertSeverity.INFO: "â„¹ï¸",
            AlertSeverity.WARNING: "âš ï¸",
            AlertSeverity.CRITICAL: "ğŸš¨",
            AlertSeverity.EMERGENCY: "ğŸ”¥"
        }
        
        icon = severity_icons.get(alert.severity, "ğŸ“¢")
        logger.warning(f"{icon} [{alert.severity.value.upper()}] {alert.title}: {alert.message}")
        return True

class WebSocketAlertHandler(AlertHandler):
    """WebSocket ì•Œë¦¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.connected_clients: Set[websockets.WebSocketServerProtocol] = set()
    
    def add_client(self, websocket):
        """í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€"""
        self.connected_clients.add(websocket)
    
    def remove_client(self, websocket):
        """í´ë¼ì´ì–¸íŠ¸ ì œê±°"""
        self.connected_clients.discard(websocket)
    
    async def send_alert(self, alert: MonitoringAlert) -> bool:
        """ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì— ì•Œë¦¼ ì „ì†¡"""
        if not self.connected_clients:
            return True
        
        message = json.dumps({
            "type": "alert",
            "data": alert.to_dict()
        })
        
        # ì—°ê²° ëŠì–´ì§„ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        disconnected = set()
        
        for client in self.connected_clients:
            try:
                await client.send(message)
            except websockets.exceptions.ConnectionClosed:
                disconnected.add(client)
            except Exception as e:
                logger.error(f"WebSocket ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
                disconnected.add(client)
        
        # ëŠì–´ì§„ ì—°ê²° ì •ë¦¬
        self.connected_clients -= disconnected
        
        return len(disconnected) == 0

# ===== ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° êµ¬í˜„ =====

class SystemMetricCollector(MetricCollector):
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def collect_metrics(self) -> List[PerformanceMetric]:
        metrics = []
        
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            metrics.append(PerformanceMetric(
                name="system.cpu.usage",
                value=cpu_percent,
                metric_type=MetricType.GAUGE,
                unit="percent"
            ))
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            memory = psutil.virtual_memory()
            metrics.append(PerformanceMetric(
                name="system.memory.usage",
                value=memory.percent,
                metric_type=MetricType.GAUGE,
                unit="percent"
            ))
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk = psutil.disk_usage('/')
            metrics.append(PerformanceMetric(
                name="system.disk.usage",
                value=(disk.used / disk.total) * 100,
                metric_type=MetricType.GAUGE,
                unit="percent"
            ))
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            net_io = psutil.net_io_counters()
            metrics.append(PerformanceMetric(
                name="system.network.bytes_sent",
                value=float(net_io.bytes_sent),
                metric_type=MetricType.COUNTER,
                unit="bytes"
            ))
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return metrics

class BatchJobMetricCollector(MetricCollector):
    """ë°°ì¹˜ ì‘ì—… ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.batch_manager = get_batch_manager()
    
    def collect_metrics(self) -> List[PerformanceMetric]:
        metrics = []
        
        try:
            # ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„
            scheduler_stats = self.batch_manager.scheduler.get_scheduler_stats()
            
            # ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ìˆ˜
            metrics.append(PerformanceMetric(
                name="batch.queue.size",
                value=float(scheduler_stats['queue_size']),
                metric_type=MetricType.GAUGE,
                unit="jobs"
            ))
            
            # ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ìˆ˜
            metrics.append(PerformanceMetric(
                name="batch.active.jobs",
                value=float(scheduler_stats['active_jobs']),
                metric_type=MetricType.GAUGE,
                unit="jobs"
            ))
            
            # ì™„ë£Œëœ ì‘ì—… ìˆ˜ (ëˆ„ì )
            metrics.append(PerformanceMetric(
                name="batch.completed.total",
                value=float(scheduler_stats['total_completed']),
                metric_type=MetricType.COUNTER,
                unit="jobs"
            ))
            
            # ì‹¤íŒ¨í•œ ì‘ì—… ìˆ˜ (ëˆ„ì )
            metrics.append(PerformanceMetric(
                name="batch.failed.total",
                value=float(scheduler_stats['total_failed']),
                metric_type=MetricType.COUNTER,
                unit="jobs"
            ))
            
            # ì„±ê³µë¥ 
            total_processed = scheduler_stats['total_completed'] + scheduler_stats['total_failed']
            if total_processed > 0:
                success_rate = (scheduler_stats['total_completed'] / total_processed) * 100
                metrics.append(PerformanceMetric(
                    name="batch.success.rate",
                    value=success_rate,
                    metric_type=MetricType.GAUGE,
                    unit="percent"
                ))
            
            # ì‘ì—… ìœ í˜•ë³„ ë©”íŠ¸ë¦­
            with self.batch_manager.scheduler.active_lock:
                job_type_counts = defaultdict(int)
                for job in self.batch_manager.scheduler.active_jobs.values():
                    job_type_counts[job.job_type.value] += 1
                
                for job_type, count in job_type_counts.items():
                    metrics.append(PerformanceMetric(
                        name="batch.active.by_type",
                        value=float(count),
                        metric_type=MetricType.GAUGE,
                        unit="jobs",
                        tags={"job_type": job_type}
                    ))
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì‘ì—… ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return metrics

# ===== ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì¶”ì ê¸° =====

class JobProgressTracker:
    """ì‘ì—… ì§„í–‰ë¥  ì¶”ì ê¸°"""
    
    def __init__(self):
        self.batch_manager = get_batch_manager()
        self.progress_info: Dict[str, JobProgressInfo] = {}
        self.lock = threading.Lock()
        
        # ì§„í–‰ë¥  ì¶”ì •ì„ ìœ„í•œ íˆìŠ¤í† ë¦¬
        self.progress_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10))
    
    def update_job_progress(
        self, 
        job_id: str, 
        progress_percent: float,
        current_stage: str = "",
        stages_completed: int = 0,
        total_stages: int = 1,
        error_message: str = "",
        warning_message: str = ""
    ) -> None:
        """ì‘ì—… ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        
        with self.lock:
            current_time = datetime.now()
            
            # ê¸°ì¡´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒˆë¡œ ìƒì„±
            if job_id in self.progress_info:
                progress_info = self.progress_info[job_id]
            else:
                # ë°°ì¹˜ ë§¤ë‹ˆì €ì—ì„œ ì‘ì—… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                job = self.batch_manager.scheduler.job_history.get(job_id)
                
                # ì‘ì—… ì •ë³´ê°€ ì—†ì–´ë„ ê¸°ë³¸ ì§„í–‰ë¥  ì •ë³´ ìƒì„± (í…ŒìŠ¤íŠ¸ ëª©ì )
                if not job:
                    logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… ID, ê¸°ë³¸ ì •ë³´ë¡œ ìƒì„±: {job_id}")
                    progress_info = JobProgressInfo(
                        job_id=job_id,
                        job_type="unknown",
                        priority="NORMAL",
                        progress_percent=0.0,
                        estimated_remaining_seconds=300,
                        current_stage="ì‹œì‘",
                        stages_completed=0,
                        total_stages=total_stages
                    )
                else:
                    progress_info = JobProgressInfo(
                        job_id=job_id,
                        job_type=job.job_type.value,
                        priority=job.priority.name,
                        progress_percent=0.0,
                        estimated_remaining_seconds=job.estimated_duration,
                        current_stage="ì‹œì‘",
                        stages_completed=0,
                        total_stages=total_stages
                    )
                
                self.progress_info[job_id] = progress_info
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_info.progress_percent = min(progress_percent, 100.0)
            progress_info.current_stage = current_stage or progress_info.current_stage
            progress_info.stages_completed = stages_completed
            progress_info.total_stages = max(total_stages, progress_info.total_stages)
            
            # ì—ëŸ¬/ê²½ê³  ë©”ì‹œì§€ ì¶”ê°€
            if error_message:
                progress_info.error_messages.append(f"{current_time.strftime('%H:%M:%S')}: {error_message}")
                # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
                progress_info.error_messages = progress_info.error_messages[-5:]
            
            if warning_message:
                progress_info.warnings.append(f"{current_time.strftime('%H:%M:%S')}: {warning_message}")
                # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
                progress_info.warnings = progress_info.warnings[-5:]
            
            # ì§„í–‰ë¥  íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ì²˜ë¦¬ëŸ‰ ê³„ì‚°ìš©)
            self.progress_history[job_id].append((current_time.timestamp(), progress_percent))
            
            # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
            self._calculate_estimated_time(job_id, progress_info)
    
    def _calculate_estimated_time(self, job_id: str, progress_info: JobProgressInfo) -> None:
        """ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°"""
        history = self.progress_history[job_id]
        
        if len(history) < 2 or progress_info.progress_percent <= 0:
            return
        
        # ìµœê·¼ ì§„í–‰ë¥  ë³€í™” ê³„ì‚°
        recent_entries = list(history)[-5:]  # ìµœê·¼ 5ê°œ ë°ì´í„°í¬ì¸íŠ¸
        
        if len(recent_entries) >= 2:
            time_diff = recent_entries[-1][0] - recent_entries[0][0]
            progress_diff = recent_entries[-1][1] - recent_entries[0][1]
            
            if time_diff > 0 and progress_diff > 0:
                # ì´ˆë‹¹ ì§„í–‰ë¥ 
                progress_rate = progress_diff / time_diff
                progress_info.throughput_per_second = progress_rate
                
                # ë‚¨ì€ ì§„í–‰ë¥ 
                remaining_progress = 100.0 - progress_info.progress_percent
                
                # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ (ì´ˆ)
                if progress_rate > 0:
                    progress_info.estimated_remaining_seconds = int(remaining_progress / progress_rate)
                else:
                    progress_info.estimated_remaining_seconds = 0
    
    def get_job_progress(self, job_id: str) -> Optional[JobProgressInfo]:
        """ì‘ì—… ì§„í–‰ë¥  ì¡°íšŒ"""
        with self.lock:
            return self.progress_info.get(job_id)
    
    def get_all_active_progress(self) -> List[JobProgressInfo]:
        """ëª¨ë“  í™œì„± ì‘ì—…ì˜ ì§„í–‰ë¥  ì¡°íšŒ"""
        with self.lock:
            # ë°°ì¹˜ ë§¤ë‹ˆì €ì˜ í™œì„± ì‘ì—…ê³¼ ë§¤ì¹­
            active_job_ids = set(self.batch_manager.scheduler.active_jobs.keys())
            
            active_progress = []
            for job_id, progress_info in self.progress_info.items():
                if job_id in active_job_ids:
                    active_progress.append(progress_info)
            
            return active_progress
    
    def cleanup_completed_jobs(self) -> None:
        """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬"""
        with self.lock:
            active_job_ids = set(self.batch_manager.scheduler.active_jobs.keys())
            
            # ë” ì´ìƒ í™œì„± ìƒíƒœê°€ ì•„ë‹Œ ì‘ì—… ì œê±°
            completed_jobs = [
                job_id for job_id in self.progress_info.keys() 
                if job_id not in active_job_ids
            ]
            
            for job_id in completed_jobs:
                del self.progress_info[job_id]
                if job_id in self.progress_history:
                    del self.progress_history[job_id]
            
            if completed_jobs:
                logger.info(f"ì™„ë£Œëœ ì‘ì—… {len(completed_jobs)}ê°œ ì •ë¦¬ë¨")

# ===== í†µí•© ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ =====

class AdvancedMonitoringService:
    """ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.batch_manager = get_batch_manager()
        self.progress_tracker = JobProgressTracker()
        
        # ì•Œë¦¼ ì²˜ë¦¬ê¸°
        self.alert_handlers: List[AlertHandler] = [
            ConsoleAlertHandler(),
            WebSocketAlertHandler()
        ]
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        self.metric_collectors: List[MetricCollector] = [
            SystemMetricCollector(),
            BatchJobMetricCollector()
        ]
        
        # ì•Œë¦¼ ê´€ë¦¬
        self.active_alerts: Dict[str, MonitoringAlert] = {}
        self.alert_history: deque = deque(maxlen=100)  # ìµœê·¼ 100ê°œ ì•Œë¦¼
        
        # ë©”íŠ¸ë¦­ ì €ì¥ì†Œ (ì¸ë©”ëª¨ë¦¬)
        self.metrics_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_enabled = True
        self.monitoring_interval = 10  # 10ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        self.alert_cooldown = 300      # 5ë¶„ê°„ ë™ì¼ ì•Œë¦¼ ë°©ì§€
        
        # ì•Œë¦¼ ì„ê³„ê°’
        self.alert_thresholds = {
            'system.cpu.usage': 85.0,
            'system.memory.usage': 90.0,
            'batch.queue.size': 50,
            'batch.success.rate': 80.0  # 80% ë¯¸ë§Œ ì‹œ ì•Œë¦¼
        }
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitoring_thread: Optional[threading.Thread] = None
        
        logger.info("ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            logger.warning("ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.monitoring_enabled = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            name="AdvancedMonitoring",
            daemon=True
        )
        self.monitoring_thread.start()
        logger.info("ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
    
    def stop_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì •ì§€"""
        self.monitoring_enabled = False
        
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=10)
        
        logger.info("ê³ ê¸‰ ëª¨ë‹ˆí„°ë§ ì •ì§€ë¨")
    
    def _monitoring_loop(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_enabled:
            try:
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                self._collect_all_metrics()
                
                # ì•Œë¦¼ í™•ì¸
                self._check_alerts()
                
                # ì§„í–‰ë¥  ì¶”ì ê¸° ì •ë¦¬
                self.progress_tracker.cleanup_completed_jobs()
                
                # ëŒ€ê¸°
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(5)
    
    def _collect_all_metrics(self) -> None:
        """ëª¨ë“  ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        all_metrics = []
        
        for collector in self.metric_collectors:
            try:
                metrics = collector.collect_metrics()
                all_metrics.extend(metrics)
            except Exception as e:
                logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨ ({collector.__class__.__name__}): {e}")
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        for metric in all_metrics:
            self.metrics_history[metric.name].append(metric)
    
    def _check_alerts(self) -> None:
        """ì•Œë¦¼ í™•ì¸ ë° ì „ì†¡"""
        current_time = datetime.now()
        
        # ìµœê·¼ ë©”íŠ¸ë¦­ ê¸°ì¤€ ì•Œë¦¼ í™•ì¸
        for metric_name, threshold in self.alert_thresholds.items():
            if metric_name in self.metrics_history:
                metrics = self.metrics_history[metric_name]
                if metrics:
                    latest_metric = metrics[-1]
                    self._check_metric_alert(latest_metric, threshold, current_time)
        
        # ë°°ì¹˜ ì‘ì—… ê´€ë ¨ ì•Œë¦¼ í™•ì¸
        self._check_batch_job_alerts(current_time)
    
    def _check_metric_alert(
        self, 
        metric: PerformanceMetric, 
        threshold: float, 
        current_time: datetime
    ) -> None:
        """ë©”íŠ¸ë¦­ ê¸°ë°˜ ì•Œë¦¼ í™•ì¸"""
        alert_id = f"metric_{metric.name}"
        
        # ì¿¨ë‹¤ìš´ í™•ì¸
        if alert_id in self.active_alerts:
            last_alert_time = self.active_alerts[alert_id].timestamp
            if (current_time - last_alert_time).total_seconds() < self.alert_cooldown:
                return
        
        # ì„ê³„ê°’ í™•ì¸
        should_alert = False
        severity = AlertSeverity.INFO
        
        if metric.name.endswith('.usage') or metric.name.endswith('.rate'):
            if metric.value > threshold:
                should_alert = True
                if metric.value > threshold * 1.1:  # 110% ì´ìƒ
                    severity = AlertSeverity.CRITICAL
                else:
                    severity = AlertSeverity.WARNING
        elif metric.name == 'batch.queue.size':
            if metric.value > threshold:
                should_alert = True
                if metric.value > threshold * 2:  # 2ë°° ì´ìƒ
                    severity = AlertSeverity.CRITICAL
                else:
                    severity = AlertSeverity.WARNING
        elif metric.name == 'batch.success.rate':
            if metric.value < threshold:
                should_alert = True
                if metric.value < threshold * 0.7:  # 70% ë¯¸ë§Œ
                    severity = AlertSeverity.CRITICAL
                else:
                    severity = AlertSeverity.WARNING
        
        if should_alert:
            alert = MonitoringAlert(
                alert_id=alert_id,
                severity=severity,
                title=f"{metric.name} ì„ê³„ê°’ ì´ˆê³¼",
                message=f"{metric.name}: {metric.value:.2f}{metric.unit} (ì„ê³„ê°’: {threshold})",
                source="metric_monitor",
                metadata={
                    "metric_name": metric.name,
                    "current_value": metric.value,
                    "threshold": threshold,
                    "unit": metric.unit
                }
            )
            
            asyncio.create_task(self._send_alert(alert))
    
    def _check_batch_job_alerts(self, current_time: datetime) -> None:
        """ë°°ì¹˜ ì‘ì—… ê´€ë ¨ ì•Œë¦¼ í™•ì¸"""
        # ì˜¤ë˜ ì‹¤í–‰ë˜ëŠ” ì‘ì—… í™•ì¸
        with self.batch_manager.scheduler.active_lock:
            for job in self.batch_manager.scheduler.active_jobs.values():
                if job.started_at:
                    runtime = (current_time - job.started_at).total_seconds()
                    expected_duration = job.estimated_duration
                    
                    # ì˜ˆìƒ ì‹œê°„ì˜ 2ë°° ì´ìƒ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°
                    if runtime > expected_duration * 2:
                        alert_id = f"long_running_job_{job.job_id}"
                        
                        if alert_id not in self.active_alerts:
                            alert = MonitoringAlert(
                                alert_id=alert_id,
                                severity=AlertSeverity.WARNING,
                                title="ì¥ì‹œê°„ ì‹¤í–‰ ì‘ì—… ê°ì§€",
                                message=f"ì‘ì—… {job.job_id}ê°€ ì˜ˆìƒ ì‹œê°„ë³´ë‹¤ ì˜¤ë˜ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ (ì‹¤í–‰ì‹œê°„: {runtime/60:.1f}ë¶„, ì˜ˆìƒ: {expected_duration/60:.1f}ë¶„)",
                                source="job_monitor",
                                metadata={
                                    "job_id": job.job_id,
                                    "job_type": job.job_type.value,
                                    "runtime_seconds": runtime,
                                    "expected_duration": expected_duration
                                }
                            )
                            
                            asyncio.create_task(self._send_alert(alert))
    
    async def _send_alert(self, alert: MonitoringAlert) -> None:
        """ì•Œë¦¼ ì „ì†¡"""
        # í™œì„± ì•Œë¦¼ì— ì¶”ê°€
        self.active_alerts[alert.alert_id] = alert
        self.alert_history.append(alert)
        
        # ëª¨ë“  ì•Œë¦¼ ì²˜ë¦¬ê¸°ì— ì „ì†¡
        for handler in self.alert_handlers:
            try:
                await handler.send_alert(alert)
            except Exception as e:
                logger.error(f"ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ ({handler.__class__.__name__}): {e}")
    
    def get_websocket_handler(self) -> WebSocketAlertHandler:
        """WebSocket ì•Œë¦¼ ì²˜ë¦¬ê¸° ë°˜í™˜"""
        for handler in self.alert_handlers:
            if isinstance(handler, WebSocketAlertHandler):
                return handler
        return None
    
    def get_monitoring_dashboard(self) -> Dict[str, Any]:
        """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ë°ì´í„°"""
        current_time = datetime.now()
        
        # ìµœì‹  ë©”íŠ¸ë¦­
        latest_metrics = {}
        for metric_name, metrics in self.metrics_history.items():
            if metrics:
                latest_metrics[metric_name] = metrics[-1].to_dict()
        
        # í™œì„± ì•Œë¦¼
        active_alerts = [alert.to_dict() for alert in self.active_alerts.values()]
        
        # ìµœê·¼ ì•Œë¦¼ (ìµœê·¼ 10ê°œ)
        recent_alerts = [alert.to_dict() for alert in list(self.alert_history)[-10:]]
        
        # ì‘ì—… ì§„í–‰ë¥ 
        active_progress = [
            progress.to_dict() 
            for progress in self.progress_tracker.get_all_active_progress()
        ]
        
        # ì‹œìŠ¤í…œ ìš”ì•½
        system_summary = self._get_system_summary(latest_metrics)
        
        return {
            "timestamp": current_time.isoformat(),
            "system_summary": system_summary,
            "latest_metrics": latest_metrics,
            "active_alerts": active_alerts,
            "recent_alerts": recent_alerts,
            "job_progress": active_progress,
            "monitoring_status": {
                "enabled": self.monitoring_enabled,
                "interval_seconds": self.monitoring_interval,
                "total_metrics_collected": sum(len(metrics) for metrics in self.metrics_history.values()),
                "total_alerts_sent": len(self.alert_history)
            }
        }
    
    def _get_system_summary(self, latest_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìš”ì•½ ì •ë³´"""
        summary = {
            "overall_health": "healthy",
            "cpu_usage": 0.0,
            "memory_usage": 0.0,
            "active_jobs": 0,
            "queue_size": 0,
            "success_rate": 100.0
        }
        
        try:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            if "system.cpu.usage" in latest_metrics:
                summary["cpu_usage"] = latest_metrics["system.cpu.usage"]["value"]
            
            if "system.memory.usage" in latest_metrics:
                summary["memory_usage"] = latest_metrics["system.memory.usage"]["value"]
            
            # ë°°ì¹˜ ì‘ì—… ë©”íŠ¸ë¦­
            if "batch.active.jobs" in latest_metrics:
                summary["active_jobs"] = int(latest_metrics["batch.active.jobs"]["value"])
            
            if "batch.queue.size" in latest_metrics:
                summary["queue_size"] = int(latest_metrics["batch.queue.size"]["value"])
            
            if "batch.success.rate" in latest_metrics:
                summary["success_rate"] = latest_metrics["batch.success.rate"]["value"]
            
            # ì „ì²´ ê±´ê°• ìƒíƒœ íŒë‹¨
            if (summary["cpu_usage"] > 90 or 
                summary["memory_usage"] > 95 or 
                len(self.active_alerts) > 5):
                summary["overall_health"] = "critical"
            elif (summary["cpu_usage"] > 80 or 
                  summary["memory_usage"] > 85 or 
                  len(self.active_alerts) > 2):
                summary["overall_health"] = "warning"
        
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return summary
    
    def acknowledge_alert(self, alert_id: str) -> bool:
        """ì•Œë¦¼ í™•ì¸ ì²˜ë¦¬"""
        if alert_id in self.active_alerts:
            self.active_alerts[alert_id].acknowledged = True
            logger.info(f"ì•Œë¦¼ í™•ì¸ë¨: {alert_id}")
            return True
        return False
    
    def resolve_alert(self, alert_id: str) -> bool:
        """ì•Œë¦¼ í•´ê²° ì²˜ë¦¬"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolved = True
            alert.acknowledged = True
            
            # í™œì„± ì•Œë¦¼ì—ì„œ ì œê±°
            del self.active_alerts[alert_id]
            
            logger.info(f"ì•Œë¦¼ í•´ê²°ë¨: {alert_id}")
            return True
        return False
    
    def get_metric_history(
        self, 
        metric_name: str, 
        minutes: int = 60
    ) -> List[Dict[str, Any]]:
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if metric_name not in self.metrics_history:
            return []
        
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        
        filtered_metrics = [
            metric.to_dict()
            for metric in self.metrics_history[metric_name]
            if metric.timestamp >= cutoff_time
        ]
        
        return filtered_metrics

# ===== ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ =====

_global_monitoring_service: Optional[AdvancedMonitoringService] = None

def get_monitoring_service() -> AdvancedMonitoringService:
    """ì „ì—­ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_monitoring_service
    
    if _global_monitoring_service is None:
        _global_monitoring_service = AdvancedMonitoringService()
    
    return _global_monitoring_service

def shutdown_monitoring_service() -> None:
    """ì „ì—­ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì¢…ë£Œ"""
    global _global_monitoring_service
    
    if _global_monitoring_service is not None:
        _global_monitoring_service.stop_monitoring()
        _global_monitoring_service = None
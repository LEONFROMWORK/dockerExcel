"""
Playwright ê¸°ë°˜ í•œêµ­ì–´ í…œí”Œë¦¿ í¬ë¡¤ëŸ¬
ì‹¤ì œ ë¸Œë¼ìš°ì € ìë™í™”ë¥¼ í†µí•œ ì¸ì¦ ë° ë‹¤ìš´ë¡œë“œ
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime
import json
import re

try:
    from playwright.async_api import async_playwright
    from playwright_stealth import Stealth

    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    try:
        from playwright.async_api import async_playwright

        PLAYWRIGHT_AVAILABLE = True
        Stealth = None  # stealth ì—†ì´ë„ ë™ì‘
    except ImportError:
        PLAYWRIGHT_AVAILABLE = False

from .korean_template_crawler import CrawledTemplate

logger = logging.getLogger(__name__)


class PlaywrightKoreanCrawler:
    """Playwright ê¸°ë°˜ í•œêµ­ì–´ í…œí”Œë¦¿ í¬ë¡¤ëŸ¬"""

    def __init__(self):
        if not PLAYWRIGHT_AVAILABLE:
            raise ImportError(
                "Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install playwright playwright-stealth"
            )

        self.base_url = "https://excel.yesform.com"
        self.login_url = "https://www.yesform.com/z_n/member/login.php"

        # ë¡œê·¸ì¸ ì •ë³´
        self.username = "j1global"
        self.password = "wpdldnjs11!"

        # ì €ì¥ ê²½ë¡œ
        self.download_dir = Path("downloads/korean_templates_playwright")
        self.metadata_dir = Path("metadata/korean_templates_playwright")
        self.reports_dir = Path("reports/korean_templates_playwright")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        for directory in [self.download_dir, self.metadata_dir, self.reports_dir]:
            directory.mkdir(parents=True, exist_ok=True)

        # ìƒíƒœ ê´€ë¦¬
        self.browser = None
        self.context = None
        self.page = None
        self.crawled_templates = []
        self.failed_downloads = []

        # ì§„í–‰ ìƒí™© ì¶”ì 
        self.progress = {
            "total_templates": 0,
            "downloaded_templates": 0,
            "failed_downloads": 0,
            "current_status": "ì¤€ë¹„ ì¤‘",
            "start_time": None,
        }

        # ì¹´í…Œê³ ë¦¬ URL ë§¤í•‘
        self.category_urls = {
            "ì—…ë¬´í”„ë¡œê·¸ë¨": "https://excel.yesform.com/docs/formList.php?division=A12B11",
            "ì—…ë¬´í…œí”Œë¦¿": "https://excel.yesform.com/docs/formList.php?division=A12B12",
            "ì°¨íŠ¸/ëŒ€ì‹œë³´ë“œ": "https://excel.yesform.com/docs/formList.php?division=A12B13",
        }

    async def start_crawling(self) -> Dict[str, Any]:
        """í¬ë¡¤ë§ ì‹œì‘"""
        logger.info("ğŸš€ Playwright ê¸°ë°˜ í¬ë¡¤ë§ ì‹œì‘")
        self.progress["start_time"] = datetime.now()
        self.progress["current_status"] = "ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘"

        try:
            # ë¸Œë¼ìš°ì € ì´ˆê¸°í™”
            await self._initialize_browser()

            # ë¡œê·¸ì¸
            self.progress["current_status"] = "ë¡œê·¸ì¸ ì¤‘"
            await self._login()

            # ê° ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§
            for category_name, category_url in self.category_urls.items():
                self.progress["current_status"] = f"ì²˜ë¦¬ ì¤‘: {category_name}"
                await self._crawl_category(category_name, category_url)

            # ê²°ê³¼ ì €ì¥
            await self._save_results()

            self.progress["current_status"] = "ì™„ë£Œ"

            return {
                "status": "success",
                "message": "Playwright í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "summary": {
                    "total_templates": len(self.crawled_templates),
                    "successful_downloads": self.progress["downloaded_templates"],
                    "failed_downloads": self.progress["failed_downloads"],
                    "duration": str(datetime.now() - self.progress["start_time"]),
                },
            }

        except Exception as e:
            logger.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.progress["current_status"] = f"ì˜¤ë¥˜: {str(e)}"
            raise

        finally:
            await self._cleanup()

    async def _initialize_browser(self):
        """ë¸Œë¼ìš°ì € ì´ˆê¸°í™”"""
        logger.info("ğŸŒ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘...")

        playwright = await async_playwright().start()

        # ë¸Œë¼ìš°ì € ì‹œì‘ (headless=Falseë¡œ ë””ë²„ê¹… ê°€ëŠ¥)
        self.browser = await playwright.chromium.launch(
            headless=True,  # Falseë¡œ ë³€ê²½í•˜ë©´ ë¸Œë¼ìš°ì €ê°€ í™”ë©´ì— ë‚˜íƒ€ë‚¨
            args=[
                "--no-sandbox",
                "--disable-blink-features=AutomationControlled",
                "--disable-dev-shm-usage",
            ],
        )

        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        self.context = await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        )

        # í˜ì´ì§€ ìƒì„±
        self.page = await self.context.new_page()

        # ê¸°ë³¸ ë´‡ ê°ì§€ ë°©ì§€ ì„¤ì •
        await self.page.add_init_script(
            """
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });

            // Chromeì—ì„œ automation ê´€ë ¨ ìš”ì†Œë“¤ ìˆ¨ê¸°ê¸°
            delete window.cdc_adoQpoasnfa76pfcZLmcfl_Array;
            delete window.cdc_adoQpoasnfa76pfcZLmcfl_Promise;
            delete window.cdc_adoQpoasnfa76pfcZLmcfl_Symbol;
        """
        )

        logger.info("âœ… ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì™„ë£Œ")

    async def _login(self):
        """ë¡œê·¸ì¸"""
        logger.info("ğŸ” ë¡œê·¸ì¸ ì¤‘...")

        try:
            # ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†
            await self.page.goto(self.login_url, wait_until="networkidle")

            # í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· (ë””ë²„ê¹…ìš©)
            await self.page.screenshot(path="login_page.png")
            logger.info("ğŸ“¸ ë¡œê·¸ì¸ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: login_page.png")

            # í˜ì´ì§€ ë‚´ìš© í™•ì¸
            page_content = await self.page.content()
            logger.info(f"ğŸ“„ ë¡œê·¸ì¸ í˜ì´ì§€ ê¸¸ì´: {len(page_content)} ë¬¸ì")

            # ë‹¤ì–‘í•œ ì…ë ¥ í•„ë“œ ì…€ë ‰í„° ì‹œë„
            username_selectors = [
                'input[name="pId"]',
                'input[name="id"]',
                'input[name="userId"]',
                'input[name="user_id"]',
                'input[id="pId"]',
                'input[id="id"]',
                "#pId",
                "#id",
            ]

            password_selectors = [
                'input[name="pPw"]',  # ì‹¤ì œ í•„ë“œëª…
                'input[name="pPwd"]',
                'input[name="pwd"]',
                'input[name="password"]',
                'input[name="passwd"]',
                'input[id="pPw"]',  # ì‹¤ì œ ID
                'input[id="pPwd"]',
                'input[id="pwd"]',
                "#pPw",  # ì‹¤ì œ ID ì…€ë ‰í„°
                "#pPwd",
                "#pwd",
            ]

            # ì‚¬ìš©ìëª… ì…ë ¥ í•„ë“œ ì°¾ê¸°
            username_element = None
            for selector in username_selectors:
                try:
                    username_element = await self.page.wait_for_selector(
                        selector, timeout=2000
                    )
                    logger.info(f"âœ… ì‚¬ìš©ìëª… í•„ë“œ ë°œê²¬: {selector}")
                    break
                except (KeyError, IndexError, AttributeError):
                    continue

            if not username_element:
                logger.error("âŒ ì‚¬ìš©ìëª… ì…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                # ëª¨ë“  input ìš”ì†Œ ì¶œë ¥
                inputs = await self.page.query_selector_all("input")
                logger.info(f"í˜ì´ì§€ì˜ ëª¨ë“  input ìš”ì†Œ: {len(inputs)}ê°œ")
                for i, input_elem in enumerate(inputs[:5]):
                    name = await input_elem.get_attribute("name") or "unnamed"
                    input_type = await input_elem.get_attribute("type") or "text"
                    logger.info(f"   {i+1}. name='{name}', type='{input_type}'")
                raise Exception("ì‚¬ìš©ìëª… ì…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í•„ë“œ ì°¾ê¸°
            password_element = None
            for selector in password_selectors:
                try:
                    password_element = await self.page.wait_for_selector(
                        selector, timeout=2000
                    )
                    logger.info(f"âœ… ë¹„ë°€ë²ˆí˜¸ í•„ë“œ ë°œê²¬: {selector}")
                    break
                except (KeyError, IndexError, AttributeError):
                    continue

            if not password_element:
                logger.error("âŒ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                raise Exception("ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ë¡œê·¸ì¸ ì •ë³´ ì…ë ¥
            await username_element.fill(self.username)
            await password_element.fill(self.password)
            logger.info("ğŸ“ ë¡œê·¸ì¸ ì •ë³´ ì…ë ¥ ì™„ë£Œ")

            # ë¡œê·¸ì¸ ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
            submit_selectors = [
                'input[type="submit"]',
                'button[type="submit"]',
                ".btn-login",
                'button:has-text("ë¡œê·¸ì¸")',
                'input[value*="ë¡œê·¸ì¸"]',
                'form input[type="image"]',
            ]

            submit_clicked = False
            for selector in submit_selectors:
                try:
                    submit_button = await self.page.query_selector(selector)
                    if submit_button:
                        await submit_button.click()
                        logger.info(f"âœ… ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­: {selector}")
                        submit_clicked = True
                        break
                except (KeyError, IndexError, AttributeError):
                    continue

            if not submit_clicked:
                # í¼ ì„œë¸Œë°‹ìœ¼ë¡œ ì‹œë„
                form = await self.page.query_selector("form")
                if form:
                    await self.page.keyboard.press("Enter")
                    logger.info("âœ… í¼ ì„œë¸Œë°‹ (Enter í‚¤)")
                    submit_clicked = True

            if not submit_clicked:
                raise Exception("ë¡œê·¸ì¸ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ë¡œê·¸ì¸ ì™„ë£Œ ëŒ€ê¸°
            await self.page.wait_for_load_state("networkidle", timeout=15000)

            # ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸
            current_url = self.page.url
            page_content = await self.page.content()

            logger.info(f"ğŸ”— ë¡œê·¸ì¸ í›„ URL: {current_url}")

            if "ë¡œê·¸ì•„ì›ƒ" in page_content or "logout" in page_content.lower():
                logger.info("âœ… ë¡œê·¸ì¸ ì„±ê³µ")
            else:
                logger.warning("âš ï¸ ë¡œê·¸ì¸ ìƒíƒœ ë¶ˆí™•ì‹¤")
                # ë¡œê·¸ì¸ í›„ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·
                await self.page.screenshot(path="after_login.png")
                logger.info("ğŸ“¸ ë¡œê·¸ì¸ í›„ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: after_login.png")

        except Exception as e:
            logger.error(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦°ìƒ·
            try:
                await self.page.screenshot(path="login_error.png")
                logger.info("ğŸ“¸ ë¡œê·¸ì¸ ì˜¤ë¥˜ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: login_error.png")
            except (KeyError, IndexError, AttributeError):
                pass
            raise

    async def _crawl_category(self, category_name: str, category_url: str):
        """ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§"""
        logger.info(f"ğŸ“‚ ì¹´í…Œê³ ë¦¬ '{category_name}' í¬ë¡¤ë§ ì‹œì‘")

        try:
            # ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ì ‘ì†
            await self.page.goto(category_url, wait_until="networkidle")

            page = 1
            max_pages = 5  # í˜ì´ì§€ ì œí•œ (ì•ˆì •ì„±ì„ ìœ„í•´)

            while page <= max_pages:
                logger.info(f"ğŸ“„ {category_name} - í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘")

                # í…œí”Œë¦¿ ë§í¬ ìˆ˜ì§‘
                template_links = await self._get_template_links()

                if not template_links:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë” ì´ìƒ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    break

                logger.info(f"ğŸ“‹ í˜ì´ì§€ {page}ì—ì„œ {len(template_links)}ê°œ í…œí”Œë¦¿ ë°œê²¬")

                # ê° í…œí”Œë¦¿ ì²˜ë¦¬ (ì²˜ìŒ 20ê°œë§Œ ì•ˆì •ì ìœ¼ë¡œ)
                for i, template_url in enumerate(template_links[:20]):
                    try:
                        logger.info(f"ğŸ” ì²˜ë¦¬ ì¤‘: {i+1}/{min(len(template_links), 20)}")
                        await self._process_template(category_name, template_url)

                        # í…œí”Œë¦¿ ê°„ ëŒ€ê¸° ì‹œê°„
                        await asyncio.sleep(1)

                    except Exception as e:
                        logger.error(f"í…œí”Œë¦¿ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue

                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                page += 1
                if page <= max_pages:
                    try:
                        next_page_url = f"{category_url}&page={page}"
                        await self.page.goto(
                            next_page_url, wait_until="networkidle", timeout=30000
                        )

                        # í˜ì´ì§€ ê°„ ëŒ€ê¸° ì‹œê°„
                        await asyncio.sleep(3)

                    except Exception as e:
                        logger.error(f"í˜ì´ì§€ ì´ë™ ì˜¤ë¥˜: {e}")
                        break

        except Exception as e:
            logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ '{category_name}' í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    async def _get_template_links(self) -> List[str]:
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ í…œí”Œë¦¿ ë§í¬ ìˆ˜ì§‘"""
        try:
            # í…œí”Œë¦¿ ë§í¬ ìš”ì†Œë“¤ ì°¾ê¸°
            link_elements = await self.page.query_selector_all('a[href*="/xls/"]')

            template_links = []
            for element in link_elements:
                href = await element.get_attribute("href")
                if href and "/xls/" in href and href.endswith(".html"):
                    if href.startswith("/"):
                        full_url = f"{self.base_url}{href}"
                    else:
                        full_url = href
                    template_links.append(full_url)

            # ì¤‘ë³µ ì œê±°
            return list(set(template_links))

        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ ë§í¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    async def _process_template(self, category_name: str, template_url: str):
        """ê°œë³„ í…œí”Œë¦¿ ì²˜ë¦¬"""
        try:
            logger.info(f"ğŸ” í…œí”Œë¦¿ ì²˜ë¦¬: {template_url}")

            # í…œí”Œë¦¿ ìƒì„¸ í˜ì´ì§€ ì ‘ì†
            await self.page.goto(template_url, wait_until="networkidle")

            # í…œí”Œë¦¿ ì •ë³´ ì¶”ì¶œ
            template_info = await self._extract_template_info(template_url)
            if not template_info:
                return

            template_info["category_major"] = category_name
            template_info["category_minor"] = "ì¼ë°˜"

            # Excel ë‹¤ìš´ë¡œë“œ ì‹œë„
            downloaded_path = await self._download_excel_file(template_info)
            if downloaded_path:
                template_info["local_path"] = str(downloaded_path)
                self.progress["downloaded_templates"] += 1
                logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {template_info['title']}")
            else:
                self.progress["failed_downloads"] += 1
                self.failed_downloads.append(template_info)
                logger.warning(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {template_info['title']}")

            # í…œí”Œë¦¿ ëª©ë¡ì— ì¶”ê°€
            crawled_template = CrawledTemplate(**template_info)
            self.crawled_templates.append(crawled_template)

        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ ì²˜ë¦¬ ì‹¤íŒ¨ ({template_url}): {e}")

    async def _extract_template_info(self, source_url: str) -> Optional[Dict[str, Any]]:
        """í…œí”Œë¦¿ ì •ë³´ ì¶”ì¶œ"""
        try:
            # ì œëª© ì¶”ì¶œ
            title_element = await self.page.query_selector("h1, .title h1")
            title = await title_element.inner_text() if title_element else "ì œëª© ì—†ìŒ"

            # ì„¤ëª… ì¶”ì¶œ
            desc_element = await self.page.query_selector("#description, .description")
            description = (
                await desc_element.inner_text() if desc_element else "ì„¤ëª… ì—†ìŒ"
            )

            # íŒŒì¼ëª… ìƒì„±
            safe_title = re.sub(r"[^\w\-_\.]", "_", title)
            file_name = f"{safe_title}.xlsx"

            return {
                "title": title.strip(),
                "description": description.strip(),
                "file_name": file_name,
                "source_url": source_url,
                "crawled_at": datetime.now().isoformat(),
                "download_url": "",  # Playwrightì—ì„œëŠ” ì§ì ‘ ë‹¤ìš´ë¡œë“œ
                "local_path": "",
                "related_files": [],
            }

        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    async def _download_excel_file(
        self, template_info: Dict[str, Any]
    ) -> Optional[Path]:
        """Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            # ì¹´í…Œê³ ë¦¬ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
            category_dir = self.download_dir / template_info["category_major"]
            category_dir.mkdir(parents=True, exist_ok=True)

            file_path = category_dir / template_info["file_name"]

            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸
            if file_path.exists():
                logger.info(f"â­ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼: {template_info['file_name']}")
                return file_path

            # í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì§ì ‘ ì¶”ì¶œ
            page_content = await self.page.content()

            # íŒŒì¼ ID ì¶”ì¶œì„ ìœ„í•œ ë‹¤ì–‘í•œ íŒ¨í„´ ì‹œë„
            import re

            # íŒ¨í„´ 1: wlog_all í•¨ìˆ˜
            wlog_matches = re.findall(r"wlog_all\('form',\s*'(\d+)'\)", page_content)

            # íŒ¨í„´ 2: URLì—ì„œ ID ì¶”ì¶œ
            url_matches = re.findall(r"/xls/(\d+)\.html", template_info["source_url"])

            # íŒ¨í„´ 3: rowid íŒŒë¼ë¯¸í„°
            rowid_matches = re.findall(r"rowid[=:](\d+)", page_content)

            file_id = None
            if wlog_matches:
                file_id = wlog_matches[0]
                logger.info(f"ğŸ“‹ wlog_allì—ì„œ íŒŒì¼ ID ë°œê²¬: {file_id}")
            elif url_matches:
                file_id = url_matches[0]
                logger.info(f"ğŸ“‹ URLì—ì„œ íŒŒì¼ ID ë°œê²¬: {file_id}")
            elif rowid_matches:
                file_id = rowid_matches[0]
                logger.info(f"ğŸ“‹ rowidì—ì„œ íŒŒì¼ ID ë°œê²¬: {file_id}")

            if not file_id:
                logger.warning("íŒŒì¼ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                # Excel ë‹¤ìš´ë¡œë“œ ë§í¬ ì§ì ‘ ì°¾ê¸° ì‹œë„
                excel_links = re.findall(
                    r'href="([^"]*dw_form\.php[^"]*)"', page_content
                )
                if excel_links:
                    # ì²« ë²ˆì§¸ Excel ë§í¬ì—ì„œ rowid ì¶”ì¶œ
                    for link in excel_links:
                        rowid_match = re.search(r"rowid=(\d+)", link)
                        if rowid_match:
                            file_id = rowid_match.group(1)
                            logger.info(f"ğŸ“‹ ë‹¤ìš´ë¡œë“œ ë§í¬ì—ì„œ íŒŒì¼ ID ë°œê²¬: {file_id}")
                            break

                if not file_id:
                    return None

            # ì§ì ‘ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
            download_url = f"https://www.yesform.com/z_n/forms/dw_form.php?mtbl=form&rowid={file_id}&type=xlsx"
            logger.info(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ URL: {download_url}")

            # ìƒˆ íƒ­ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
            download_page = await self.context.new_page()

            try:
                # ë‹¤ìš´ë¡œë“œ ëŒ€ê¸° ì„¤ì •
                async with download_page.expect_download(
                    timeout=30000
                ) as download_info:
                    # ë‹¤ìš´ë¡œë“œ URLë¡œ ì´ë™
                    await download_page.goto(download_url)

                download = await download_info.value

                # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì €ì¥
                await download.save_as(file_path)

                # íŒŒì¼ ê²€ì¦
                if await self._verify_excel_file(file_path):
                    logger.info(
                        f"ğŸ’¾ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {template_info['file_name']}"
                    )
                    return file_path
                else:
                    if file_path.exists():
                        file_path.unlink()  # ì˜ëª»ëœ íŒŒì¼ ì‚­ì œ
                    logger.warning(f"âŒ ì˜ëª»ëœ íŒŒì¼ í˜•ì‹: {template_info['file_name']}")
                    return None

            except Exception as download_error:
                logger.warning(f"ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {download_error}")

                # ëŒ€ì²´ ë°©ë²•: ì¼ë°˜ HTTP ìš”ì²­ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
                response = await download_page.goto(
                    download_url, wait_until="networkidle"
                )

                if response and response.status == 200:
                    content_type = response.headers.get("content-type", "").lower()

                    if "html" not in content_type:
                        # íŒŒì¼ ë‚´ìš© ì½ê¸°
                        content = await response.body()

                        # íŒŒì¼ ì €ì¥
                        with open(file_path, "wb") as f:
                            f.write(content)

                        # íŒŒì¼ ê²€ì¦
                        if await self._verify_excel_file(file_path):
                            logger.info(
                                f"ğŸ’¾ HTTP ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {template_info['file_name']}"
                            )
                            return file_path
                        else:
                            if file_path.exists():
                                file_path.unlink()
                            logger.warning(
                                f"âŒ HTTP ë‹¤ìš´ë¡œë“œ íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜: {template_info['file_name']}"
                            )
                            return None
                    else:
                        logger.warning(
                            f"âŒ HTML ì‘ë‹µ ë°˜í™˜ (ì¸ì¦ ì‹¤íŒ¨): {template_info['file_name']}"
                        )
                        return None
                else:
                    logger.warning(
                        f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨: {response.status if response else 'No response'}"
                    )
                    return None

            finally:
                await download_page.close()

        except Exception as e:
            logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    async def _verify_excel_file(self, file_path: Path) -> bool:
        """Excel íŒŒì¼ ê²€ì¦"""
        try:
            if not file_path.exists() or file_path.stat().st_size < 1024:
                return False

            with open(file_path, "rb") as f:
                header = f.read(4)
                # Excel íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
                return header.startswith(b"PK") or header.startswith(  # XLSX (ZIP ê¸°ë°˜)
                    b"\xd0\xcf\x11\xe0"
                )  # XLS (OLE ê¸°ë°˜)

        except Exception:
            return False

    async def _save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        logger.info("ğŸ’¾ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì¤‘...")

        try:
            results = {
                "crawling_info": {
                    "start_time": self.progress["start_time"].isoformat(),
                    "end_time": datetime.now().isoformat(),
                    "total_templates": len(self.crawled_templates),
                    "successful_downloads": self.progress["downloaded_templates"],
                    "failed_downloads": self.progress["failed_downloads"],
                    "method": "playwright",
                },
                "templates": [
                    {
                        "title": t.title,
                        "description": t.description,
                        "category_major": t.category_major,
                        "category_minor": t.category_minor,
                        "file_name": t.file_name,
                        "source_url": t.source_url,
                        "crawled_at": t.crawled_at,
                        "local_path": getattr(t, "local_path", ""),
                        "related_files": t.related_files,
                    }
                    for t in self.crawled_templates
                ],
                "failed_downloads": self.failed_downloads,
            }

            results_file = (
                self.metadata_dir
                / f"playwright_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )

            with open(results_file, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_file}")

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")

        try:
            if self.page:
                await self.page.close()
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
        except Exception as e:
            logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def get_progress(self) -> Dict[str, Any]:
        """ì§„í–‰ ìƒí™© ë°˜í™˜"""
        if self.progress["start_time"]:
            duration = datetime.now() - self.progress["start_time"]
            self.progress["duration"] = str(duration)

        return self.progress.copy()


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
playwright_korean_crawler = PlaywrightKoreanCrawler()
